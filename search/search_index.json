{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SparseViz Documentation Introduction Welcome to the documentation of SparseViz, a comprehensive library designed for efficient and intuitive handling of sparse data structures. In the realm of data processing and analysis, sparse data structures are pivotal for managing datasets with predominantly empty or zero-valued elements. SparseViz emerges as a versatile tool, bridging the gap between the complexity of sparse data operations and the need for a user-friendly approach. Core Principle SparseViz is built upon the principle of simplifying the interaction with sparse data structures. Whether you are a data scientist, a researcher, or a developer working with large, sparse datasets, SparseViz offers a suite of functionalities that cater to your needs. This library not only facilitates the efficient representation and manipulation of sparse data but also extends its capabilities to various operations such as implementing orderings, executing kernels, and visualizing them. Moreover, SparseViz is not just a tool; it's a growing ecosystem. We've designed it with extensibility in mind, allowing for continuous development and integration of new features and methods. Key Features of SparseViz As indicated, SparseViz is not just a tool; it is a dynamic and expanding ecosystem thoughtfully crafted to cater to a wide range of applications involving sparse data structures. Its capabilities are diverse and powerful, designed to address the various challenges and needs encountered in working with sparse data. Here are the key features that make SparseViz an indispensable library: Representation of Sparse Data Structures: SparseViz excels in the efficient handling and representation of sparse matrices and tensors, making it easier to work with large, sparse datasets. Comprehensive Operations: The library supports a broad spectrum of operations on sparse data structures. From basic manipulations to more complex transformations, SparseViz ensures that these operations are both efficient and intuitive. Flexible Ordering Systems: SparseViz allows for customizable ordering of sparse data structures. This feature is particularly useful for optimizing data (to increase cache-hit) for specific algorithms or processing techniques. Kernel Execution: With SparseViz, users can execute their customized kernels on sparse data. This functionality is essential for understanding the efficiency of the implemented orderings in practical terms. Efficient Storage Solutions: The library offers optimized storage solutions for sparse data. This ensures that large datasets are not only stored efficiently but are also easily retrievable for future use. Advanced Visualization Tools: One of the standout features of SparseViz is its capability to visualize sparse data structures. This tool is invaluable for understanding complex data patterns and for communicating findings in a clear and impactful way. Extensibility At SparseViz, we encourage and support our users to not only use the existing functionalities but to also contribute to the library's growth by implementing their orderings, writing custom kernels, and extending the library in various ways. To facilitate this, we have established a robust infrastructure that allows for seamless customization and extension. There are four primary ways you can customize and extend the library: Adding Matrix Ordering Adding Tensor Ordering Adding Matrix Kernels 3.1. Adding CPU Matrix Kernels 3.2. Adding GPU Matrix Kernels Adding Tensor Kernels 4.1. Adding CPU Tensor Kernels 4.2. Adding GPU Tensor Kernels Before delving into the specifics of each extension method, we will first introduce you to the config file. The config file is a crucial component of SparseViz, allowing for tailored library configuration and setup. Understanding its role and usage is key to effectively extending and customizing SparseViz.","title":"Home"},{"location":"#sparseviz-documentation","text":"","title":"SparseViz Documentation"},{"location":"#introduction","text":"Welcome to the documentation of SparseViz, a comprehensive library designed for efficient and intuitive handling of sparse data structures. In the realm of data processing and analysis, sparse data structures are pivotal for managing datasets with predominantly empty or zero-valued elements. SparseViz emerges as a versatile tool, bridging the gap between the complexity of sparse data operations and the need for a user-friendly approach.","title":"Introduction"},{"location":"#core-principle","text":"SparseViz is built upon the principle of simplifying the interaction with sparse data structures. Whether you are a data scientist, a researcher, or a developer working with large, sparse datasets, SparseViz offers a suite of functionalities that cater to your needs. This library not only facilitates the efficient representation and manipulation of sparse data but also extends its capabilities to various operations such as implementing orderings, executing kernels, and visualizing them. Moreover, SparseViz is not just a tool; it's a growing ecosystem. We've designed it with extensibility in mind, allowing for continuous development and integration of new features and methods.","title":"Core Principle"},{"location":"#key-features-of-sparseviz","text":"As indicated, SparseViz is not just a tool; it is a dynamic and expanding ecosystem thoughtfully crafted to cater to a wide range of applications involving sparse data structures. Its capabilities are diverse and powerful, designed to address the various challenges and needs encountered in working with sparse data. Here are the key features that make SparseViz an indispensable library: Representation of Sparse Data Structures: SparseViz excels in the efficient handling and representation of sparse matrices and tensors, making it easier to work with large, sparse datasets. Comprehensive Operations: The library supports a broad spectrum of operations on sparse data structures. From basic manipulations to more complex transformations, SparseViz ensures that these operations are both efficient and intuitive. Flexible Ordering Systems: SparseViz allows for customizable ordering of sparse data structures. This feature is particularly useful for optimizing data (to increase cache-hit) for specific algorithms or processing techniques. Kernel Execution: With SparseViz, users can execute their customized kernels on sparse data. This functionality is essential for understanding the efficiency of the implemented orderings in practical terms. Efficient Storage Solutions: The library offers optimized storage solutions for sparse data. This ensures that large datasets are not only stored efficiently but are also easily retrievable for future use. Advanced Visualization Tools: One of the standout features of SparseViz is its capability to visualize sparse data structures. This tool is invaluable for understanding complex data patterns and for communicating findings in a clear and impactful way.","title":"Key Features of SparseViz"},{"location":"#extensibility","text":"At SparseViz, we encourage and support our users to not only use the existing functionalities but to also contribute to the library's growth by implementing their orderings, writing custom kernels, and extending the library in various ways. To facilitate this, we have established a robust infrastructure that allows for seamless customization and extension. There are four primary ways you can customize and extend the library: Adding Matrix Ordering Adding Tensor Ordering Adding Matrix Kernels 3.1. Adding CPU Matrix Kernels 3.2. Adding GPU Matrix Kernels Adding Tensor Kernels 4.1. Adding CPU Tensor Kernels 4.2. Adding GPU Tensor Kernels Before delving into the specifics of each extension method, we will first introduce you to the config file. The config file is a crucial component of SparseViz, allowing for tailored library configuration and setup. Understanding its role and usage is key to effectively extending and customizing SparseViz.","title":"Extensibility"},{"location":"addingCPUMatrixKernel/","text":"Tutorial 4.1: How to Add CPU Matrix Kernel SparseViz allows 2 types of matrix kernels to be added to the library externally, CPU and GPU kernels. All CPU kernels can be written in parallel using OpenMP. All GPU kernels, on the other hand, can be written in parallel using Cuda. In this tutorial, we will analyze CPU matrix kernels, especially how they can be added to the SparseViz library. All matrix kernels should be derived from the abstract class named MatrixKernelFunction in the SparseViz library. This abstract class provides various functionalities to ease the implementation of derived classes aiming to provide kernels for sparse matrices. MatrixKernelFunction dictates all its child classes to override 3 public pure virtual functions to complete their implementation. These methods are: virtual bool init(const SparseMatrix& A); This method could be thought of as a constructor for the child class. It is guaranteed that this method will be called before the execution of every matrix kernel. The only difference it has with a traditional constructor is that it is a boolean-returning function. In case there are some circumstances in which user-defined matrix kernels are not desired to be executed on some type of sparse matrices, it can easily be programmed within that init method with a return value of \"false\" that would eliminate the run of subsequent methods of the class, ultimately leading to the termination of the execution of the kernel. One way to use this functionality is if a user-defined kernel should be executed on sparse matrices that are pattern symmetric, this check could be done in the init function definition like so: bool SequentialBFS::init(const SparseMatrix &A) { if (!A.isPatternSymmetric()) { return false; } } This will guarantee that the kernel will never be executed on a matrix without having pattern symmetry. virtual void preprocess(const SparseMatrix& A); Matrix kernels could be executed from within the config file with a specification of the number of iterations to be given as an argument. This iteration number could be from 1 to many, depending on the user's preference. This iteration and the for loop that enables it are controlled by the base class MatrixKernelFunction. The preprocess method comes into play at the very first method to be called upon at the start of the iteration. In the implementation of this method, we give opportunity to users to preprocess any data or data structures, be it their initialization or their population, to be used during the current iteration of the for loop. It is guaranteed that this preprocess will be called as the first method in each iteration and the duration it took to complete this method will never be reflected in the overall duration kernel has taken to be executed. Because users cannot control the flow of the matrix kernel execution and thus cannot pass any additional parameters to the functionBody method - actual kernel function -, the only way it can use the variables initialized in it is by declaring them as member variables of the class to be used them in the actual kernel function. virtual void functionBody(const SparseMatrix& A, int iterNumber); As a last step user-defined child classes should complete their implementation by providing the last pure virtual function a definition that will carry out the actual logic of the matrix kernel. Within that method, it is expected the users write the logic of the matrix kernel that is executed on every ordered matrix indicated in the config file - except ones that failed to proceed to this function because the init method of the kernel returned false for them -. This function accepts an additional integer parameter named iterNumber, which indicates the number of consecutive times the functionBody has been called. One important remark we need to make for our matrix kernel structure in SparseViz is that during the execution of a kernel, all other threads working for SparseViz process are temporarily stopped to be able to provide all computational resources to the actual kernel execution and to make experiments as realistic as possible. Having learned each method we need to override in user-defined kernels we can complete the declaration and the implementation of our kernel named AddingCPUMatrixKernel under the directories SparseViz/include/Kernel/Matrix/CPU and SparseViz/src/Kernel/Matrix/CPU, respectively. AddingCPUMatrixKernel.h #include \"MatrixKernelFunction.h\" class AddingCPUMatrixKernel: public MatrixKernelFunction { public: AddingCPUMatrixKernel(const std::string& kernelName, const std::vector<int>& threadCounts, const std::string& schedulingPolicy, int chunkSize, int nRun, int nIgnore) : MatrixKernelFunction(kernelName, threadCounts, schedulingPolicy, chunkSize, nRun, nIgnore) {} virtual ~AddingCPUMatrixKernel() override; virtual bool init(const SparseMatrix& A) override; virtual void preprocess(const SparseMatrix& A) override; virtual void functionBody(const SparseMatrix& A, int iterNumber); }; One extension we made for the class declaration on top of the 3 methods that MatrixKernelFunction dictates its child class to override is the virtual destructor. If anywhere during the init or in the preprocess method you allocated memory on the heap or you made a process requiring a cleanup (like opening a file or making a database connection), then in the virtual destructor, it is also your responsibility to clean all them up. Also, in the constructor that has an empty implementation, we did not forget to initialize the parent class with the parameters provided to the child class constructor. To remember what these parameters refer to, you can do so by looking at tutorial 1, how to use the config file. AddingCPUMatrixKernel.cpp #include \"AddingCPUMatrixKernel.h\" bool AddingCPUMatrixKernel::init(const SparseMatrix &A) { if (!A.isPatternSymmetric()) { std::cout << \"AddingCPUMatrixKernel is terminating: matrix needs to be pattern symmetric\" << std::endl; return false; } // Your initialization code goes here. return true; } AddingCPUMatrixKernel::~AddingCPUMatrixKernel() { // Your destructor code goes here. } void AddingCPUMatrixKernel::preprocess(const SparseMatrix& A) { // Your preprocess code goes here. } void AddingCPUMatrixKernel::functionBody(const SparseMatrix& A, int iterNumber) { // Your function body code goes here. } The remaining steps to integrate the matrix kernel into SparseViz closely mirror those for adding matrix ordering. Initially, we must incorporate our class declaration and implementation into the CMakeLists.txt. Following this, we will introduce our matrix kernel definition into the SparseVizEngine, enabling the library to recognize and utilize this new kernel. CMakeLists.txt set(HEADER_FILES --- OTHER HEADER FILES (CROPPED) --- include/Kernel/Matrix/CPU/AddingCPUMatrixKernel.h ) set(SOURCE_FILES --- OTHER SOURCE FILES (CROPPED) --- src/Kernel/Matrix/CPU/AddingCPUMatrixKernel.cpp ) SparseVizEngine.h #include \"AddingCPUMatrixKernel.h\" SparseVizEngine.cpp MatrixKernelFunction *SparseVizEngine::matrixKernelFactory(const std::string &kernelName, const std::vector<int>& threadCounts, const std::string &schedulingPolicy, int chunkSize, int nRun, int nIgnore) { --- OTHER KERNEL CLASSES (CROPPED) --- else if (kernelName == \"AddingCPUMatrixKernel\") { return new AddingCPUMatrixKernel(kernelName, threadCounts, schedulingPolicy, chunkSize, nRun, nIgnore); } return nullptr; } Having made all of these steps, we can safely run our library with an absolute path pointing to our config file in which we indicated our new matrix kernel named AddingCPUMatrixKernel under the section *MATRIX_KERNELS* to make it get executed on each ordered matrices, like so: config *MATRIX_KERNELS* AddingCPUMatrixKernel | WeHaveAddedACPUMatrixKernel | 1/2/4/6/8/16 | dynamic | 256 | 10 | 2 This concludes tutorial 4.1, the way to add CPU matrix kernels into the library. In tutorial 4.2, its GPU counterpart will be explained.","title":"Adding CPU Matrix Kernel"},{"location":"addingCPUMatrixKernel/#tutorial-41-how-to-add-cpu-matrix-kernel","text":"SparseViz allows 2 types of matrix kernels to be added to the library externally, CPU and GPU kernels. All CPU kernels can be written in parallel using OpenMP. All GPU kernels, on the other hand, can be written in parallel using Cuda. In this tutorial, we will analyze CPU matrix kernels, especially how they can be added to the SparseViz library. All matrix kernels should be derived from the abstract class named MatrixKernelFunction in the SparseViz library. This abstract class provides various functionalities to ease the implementation of derived classes aiming to provide kernels for sparse matrices. MatrixKernelFunction dictates all its child classes to override 3 public pure virtual functions to complete their implementation. These methods are: virtual bool init(const SparseMatrix& A); This method could be thought of as a constructor for the child class. It is guaranteed that this method will be called before the execution of every matrix kernel. The only difference it has with a traditional constructor is that it is a boolean-returning function. In case there are some circumstances in which user-defined matrix kernels are not desired to be executed on some type of sparse matrices, it can easily be programmed within that init method with a return value of \"false\" that would eliminate the run of subsequent methods of the class, ultimately leading to the termination of the execution of the kernel. One way to use this functionality is if a user-defined kernel should be executed on sparse matrices that are pattern symmetric, this check could be done in the init function definition like so: bool SequentialBFS::init(const SparseMatrix &A) { if (!A.isPatternSymmetric()) { return false; } } This will guarantee that the kernel will never be executed on a matrix without having pattern symmetry. virtual void preprocess(const SparseMatrix& A); Matrix kernels could be executed from within the config file with a specification of the number of iterations to be given as an argument. This iteration number could be from 1 to many, depending on the user's preference. This iteration and the for loop that enables it are controlled by the base class MatrixKernelFunction. The preprocess method comes into play at the very first method to be called upon at the start of the iteration. In the implementation of this method, we give opportunity to users to preprocess any data or data structures, be it their initialization or their population, to be used during the current iteration of the for loop. It is guaranteed that this preprocess will be called as the first method in each iteration and the duration it took to complete this method will never be reflected in the overall duration kernel has taken to be executed. Because users cannot control the flow of the matrix kernel execution and thus cannot pass any additional parameters to the functionBody method - actual kernel function -, the only way it can use the variables initialized in it is by declaring them as member variables of the class to be used them in the actual kernel function. virtual void functionBody(const SparseMatrix& A, int iterNumber); As a last step user-defined child classes should complete their implementation by providing the last pure virtual function a definition that will carry out the actual logic of the matrix kernel. Within that method, it is expected the users write the logic of the matrix kernel that is executed on every ordered matrix indicated in the config file - except ones that failed to proceed to this function because the init method of the kernel returned false for them -. This function accepts an additional integer parameter named iterNumber, which indicates the number of consecutive times the functionBody has been called. One important remark we need to make for our matrix kernel structure in SparseViz is that during the execution of a kernel, all other threads working for SparseViz process are temporarily stopped to be able to provide all computational resources to the actual kernel execution and to make experiments as realistic as possible. Having learned each method we need to override in user-defined kernels we can complete the declaration and the implementation of our kernel named AddingCPUMatrixKernel under the directories SparseViz/include/Kernel/Matrix/CPU and SparseViz/src/Kernel/Matrix/CPU, respectively. AddingCPUMatrixKernel.h #include \"MatrixKernelFunction.h\" class AddingCPUMatrixKernel: public MatrixKernelFunction { public: AddingCPUMatrixKernel(const std::string& kernelName, const std::vector<int>& threadCounts, const std::string& schedulingPolicy, int chunkSize, int nRun, int nIgnore) : MatrixKernelFunction(kernelName, threadCounts, schedulingPolicy, chunkSize, nRun, nIgnore) {} virtual ~AddingCPUMatrixKernel() override; virtual bool init(const SparseMatrix& A) override; virtual void preprocess(const SparseMatrix& A) override; virtual void functionBody(const SparseMatrix& A, int iterNumber); }; One extension we made for the class declaration on top of the 3 methods that MatrixKernelFunction dictates its child class to override is the virtual destructor. If anywhere during the init or in the preprocess method you allocated memory on the heap or you made a process requiring a cleanup (like opening a file or making a database connection), then in the virtual destructor, it is also your responsibility to clean all them up. Also, in the constructor that has an empty implementation, we did not forget to initialize the parent class with the parameters provided to the child class constructor. To remember what these parameters refer to, you can do so by looking at tutorial 1, how to use the config file. AddingCPUMatrixKernel.cpp #include \"AddingCPUMatrixKernel.h\" bool AddingCPUMatrixKernel::init(const SparseMatrix &A) { if (!A.isPatternSymmetric()) { std::cout << \"AddingCPUMatrixKernel is terminating: matrix needs to be pattern symmetric\" << std::endl; return false; } // Your initialization code goes here. return true; } AddingCPUMatrixKernel::~AddingCPUMatrixKernel() { // Your destructor code goes here. } void AddingCPUMatrixKernel::preprocess(const SparseMatrix& A) { // Your preprocess code goes here. } void AddingCPUMatrixKernel::functionBody(const SparseMatrix& A, int iterNumber) { // Your function body code goes here. } The remaining steps to integrate the matrix kernel into SparseViz closely mirror those for adding matrix ordering. Initially, we must incorporate our class declaration and implementation into the CMakeLists.txt. Following this, we will introduce our matrix kernel definition into the SparseVizEngine, enabling the library to recognize and utilize this new kernel. CMakeLists.txt set(HEADER_FILES --- OTHER HEADER FILES (CROPPED) --- include/Kernel/Matrix/CPU/AddingCPUMatrixKernel.h ) set(SOURCE_FILES --- OTHER SOURCE FILES (CROPPED) --- src/Kernel/Matrix/CPU/AddingCPUMatrixKernel.cpp ) SparseVizEngine.h #include \"AddingCPUMatrixKernel.h\" SparseVizEngine.cpp MatrixKernelFunction *SparseVizEngine::matrixKernelFactory(const std::string &kernelName, const std::vector<int>& threadCounts, const std::string &schedulingPolicy, int chunkSize, int nRun, int nIgnore) { --- OTHER KERNEL CLASSES (CROPPED) --- else if (kernelName == \"AddingCPUMatrixKernel\") { return new AddingCPUMatrixKernel(kernelName, threadCounts, schedulingPolicy, chunkSize, nRun, nIgnore); } return nullptr; } Having made all of these steps, we can safely run our library with an absolute path pointing to our config file in which we indicated our new matrix kernel named AddingCPUMatrixKernel under the section *MATRIX_KERNELS* to make it get executed on each ordered matrices, like so: config *MATRIX_KERNELS* AddingCPUMatrixKernel | WeHaveAddedACPUMatrixKernel | 1/2/4/6/8/16 | dynamic | 256 | 10 | 2 This concludes tutorial 4.1, the way to add CPU matrix kernels into the library. In tutorial 4.2, its GPU counterpart will be explained.","title":"Tutorial 4.1: How to Add CPU Matrix Kernel"},{"location":"addingCPUTensorKernel/","text":"Tutorial 5.1: How to Add CPU Tensor Kernel SparseViz allows 2 types of tensor kernels to be added to the library externally, CPU and GPU kernels. All CPU kernels can be written in parallel using OpenMP. All GPU kernels, on the other hand, can be written in parallel using Cuda. In this tutorial, we will analyze CPU tensor kernels, especially how they can be added to the SparseViz library. All tensor kernels should be derived from the abstract class named TensorKernelFunction in the SparseViz library. This abstract class provides various functionalities to ease the implementation of derived classes aiming to provide kernels for sparse tensors. TensorKernelFunction dictates all its child classes to override 3 public pure virtual functions to complete their implementation. These methods are: virtual bool init(const SparseTensor& A); This method could be thought of as a constructor for the child class. It is guaranteed that this method will be called before the execution of every tensor kernel. The only difference it has with a traditional constructor is that it is a boolean-returning function. In case there are some circumstances in which user-defined tensor kernels are not desired to be executed on some type of sparse matrices, it can easily be programmed within that init method with a return value of \"false\" that would eliminate the run of subsequent methods of the class, ultimately leading to the termination of the execution of the kernel. virtual void preprocess(const SparseTensor& A); Tensor kernels could be executed from within the config file with a specification of the number of iterations to be given as an argument. This iteration number could be from 1 to many, depending on the user's preference. This iteration and the for loop that enables it is controlled by the base class TensorKernelFunction. The preprocess method comes into play at the very first method to be called upon at the start of the iteration. In the implementation of this method, we give opportunity to users to preprocess any data or data structures, be it their initialization or their population, to be used during the current iteration of the for loop. It is guaranteed that this preprocess will be called as the first method in each iteration and the duration it took to complete this method will never be reflected in the overall duration kernel has taken to be executed. Because users cannot control the flow of the tensor kernel execution and thus cannot pass any additional parameters to the functionBody method - actual kernel function -, the only way it can use the variables initialized in it is by declaring them as member variables of the class to be used them in the actual kernel function. virtual void functionBody(const SparseTensor& A, int iterNumber); As a last step user-defined child classes should complete their implementation by providing the last pure virtual function a definition that will carry out the actual logic of the tensor kernel. Within that method, it is expected the users write the logic of the tensor kernel that is executed on every ordered tensor indicated in the config file - except ones that failed to proceed to this function because the init method of the kernel returned false for them -. This function accepts an additional integer parameter named iterNumber, which indicates the number of consecutive times the functionBody has been called. One important remark we need to make for our tensor kernel structure in SparseViz is that during the execution of a kernel, all other threads working for SparseViz process are temporarily stopped to be able to provide all computational resources to the actual kernel execution and to make experiments as realistic as possible. Having learned each method we need to override in user-defined kernels we can complete the declaration and the implementation of our kernel named AddingCPUTensorKernel under the directories SparseViz/include/Kernel/Tensor/CPU and SparseViz/src/Kernel/Tensor/CPU, respectively. AddingCPUTensorKernel.h #include \"TensorKernelFunction.h\" class AddingCPUTensorKernel: public TensorKernelFunction { public: AddingCPUTensorKernel(const std::string& kernelName, const std::vector<int>& threadCounts, const std::string& schedulingPolicy, int chunkSize, int nRun, int nIgnore) : TensorKernelFunction(kernelName, threadCounts, schedulingPolicy, chunkSize, nRun, nIgnore) {} virtual ~AddingCPUTensorKernel() override; virtual bool init(const SparseTensor& A) override; virtual void preprocess(const SparseTensor& A) override; virtual void functionBody(const SparseTensor& A, int iterNumber); }; One extension we made for the class declaration on top of the 3 methods that TensorKernelFunction dictates its child class to override is the virtual destructor. If anywhere during the init or in the preprocess method you allocated memory on the heap or you made a process requiring a cleanup (like opening a file or making a database connection), then in the virtual destructor, it is also your responsibility to clean all them up. Also, in the constructor that has an empty implementation, we did not forget to initialize the parent class with the parameters provided to the child class constructor. To remember what these parameters refer to, you can do so by looking at tutorial 1, how to use the config file. AddingCPUTensorKernel.cpp #include \"AddingCPUTensorKernel.h\" bool AddingCPUTensorKernel::init(const SparseTensor &A) { if (// some checks may be done) { return false; } // Your initialization code goes here return true; } AddingCPUTensorKernel::~AddingCPUTensorKernel() { // Your destructor code goes here. } void AddingCPUTensorKernel::preprocess(const SparseTensor& A) { // Your preprocess code goes here. } void AddingCPUTensorKernel::functionBody(const SparseTensor& A, int iterNumber) { // Your function body code goes here. } The remaining steps to integrate the tensor kernel into SparseViz closely mirror those for adding tensor ordering. Initially, we must incorporate our class declaration and implementation into the CMakeLists.txt. Following this, we will introduce our tensor kernel definition into the SparseVizEngine, enabling the library to recognize and utilize this new kernel. CMakeLists.txt set(HEADER_FILES --- OTHER HEADER FILES (CROPPED) --- include/Kernel/Tensor/CPU/AddingCPUTensorKernel.h ) set(SOURCE_FILES --- OTHER SOURCE FILES (CROPPED) --- src/Kernel/Tensor/CPU/AddingCPUTensorKernel.cpp ) SparseVizEngine.h #include \"AddingCPUTensorKernel.h\" SparseVizEngine.cpp TensorKernelFunction *SparseVizEngine::tensorKernelFactory(const std::string &kernelName, const std::vector<int>& threadCounts, const std::string &schedulingPolicy, int chunkSize, int nRun, int nIgnore) { --- OTHER KERNEL CLASSES (CROPPED) --- else if (kernelName == \"AddingCPUTensorKernel\") { return new AddingCPUTensorKernel(kernelName, threadCounts, schedulingPolicy, chunkSize, nRun, nIgnore); } return nullptr; } Having made all of these steps, we can safely run our library with an absolute path pointing to our config file in which we indicated our new tensor kernel named AddingCPUTensorKernel under the section *TENSOR_KERNELS* to make it get executed on each ordered matrices, like so: config *TENSOR_KERNELS* AddingCPUTensorKernel | WeHaveAddedACPUTensorKernel | 1/2/4/6/8/16 | dynamic | 256 | 10 | 2 This concludes tutorial 5.1, the way to add CPU tensor kernels into the library. In tutorial 5.2, its GPU counterpart will be explained.","title":"Adding CPU Tensor Kernel"},{"location":"addingCPUTensorKernel/#tutorial-51-how-to-add-cpu-tensor-kernel","text":"SparseViz allows 2 types of tensor kernels to be added to the library externally, CPU and GPU kernels. All CPU kernels can be written in parallel using OpenMP. All GPU kernels, on the other hand, can be written in parallel using Cuda. In this tutorial, we will analyze CPU tensor kernels, especially how they can be added to the SparseViz library. All tensor kernels should be derived from the abstract class named TensorKernelFunction in the SparseViz library. This abstract class provides various functionalities to ease the implementation of derived classes aiming to provide kernels for sparse tensors. TensorKernelFunction dictates all its child classes to override 3 public pure virtual functions to complete their implementation. These methods are: virtual bool init(const SparseTensor& A); This method could be thought of as a constructor for the child class. It is guaranteed that this method will be called before the execution of every tensor kernel. The only difference it has with a traditional constructor is that it is a boolean-returning function. In case there are some circumstances in which user-defined tensor kernels are not desired to be executed on some type of sparse matrices, it can easily be programmed within that init method with a return value of \"false\" that would eliminate the run of subsequent methods of the class, ultimately leading to the termination of the execution of the kernel. virtual void preprocess(const SparseTensor& A); Tensor kernels could be executed from within the config file with a specification of the number of iterations to be given as an argument. This iteration number could be from 1 to many, depending on the user's preference. This iteration and the for loop that enables it is controlled by the base class TensorKernelFunction. The preprocess method comes into play at the very first method to be called upon at the start of the iteration. In the implementation of this method, we give opportunity to users to preprocess any data or data structures, be it their initialization or their population, to be used during the current iteration of the for loop. It is guaranteed that this preprocess will be called as the first method in each iteration and the duration it took to complete this method will never be reflected in the overall duration kernel has taken to be executed. Because users cannot control the flow of the tensor kernel execution and thus cannot pass any additional parameters to the functionBody method - actual kernel function -, the only way it can use the variables initialized in it is by declaring them as member variables of the class to be used them in the actual kernel function. virtual void functionBody(const SparseTensor& A, int iterNumber); As a last step user-defined child classes should complete their implementation by providing the last pure virtual function a definition that will carry out the actual logic of the tensor kernel. Within that method, it is expected the users write the logic of the tensor kernel that is executed on every ordered tensor indicated in the config file - except ones that failed to proceed to this function because the init method of the kernel returned false for them -. This function accepts an additional integer parameter named iterNumber, which indicates the number of consecutive times the functionBody has been called. One important remark we need to make for our tensor kernel structure in SparseViz is that during the execution of a kernel, all other threads working for SparseViz process are temporarily stopped to be able to provide all computational resources to the actual kernel execution and to make experiments as realistic as possible. Having learned each method we need to override in user-defined kernels we can complete the declaration and the implementation of our kernel named AddingCPUTensorKernel under the directories SparseViz/include/Kernel/Tensor/CPU and SparseViz/src/Kernel/Tensor/CPU, respectively. AddingCPUTensorKernel.h #include \"TensorKernelFunction.h\" class AddingCPUTensorKernel: public TensorKernelFunction { public: AddingCPUTensorKernel(const std::string& kernelName, const std::vector<int>& threadCounts, const std::string& schedulingPolicy, int chunkSize, int nRun, int nIgnore) : TensorKernelFunction(kernelName, threadCounts, schedulingPolicy, chunkSize, nRun, nIgnore) {} virtual ~AddingCPUTensorKernel() override; virtual bool init(const SparseTensor& A) override; virtual void preprocess(const SparseTensor& A) override; virtual void functionBody(const SparseTensor& A, int iterNumber); }; One extension we made for the class declaration on top of the 3 methods that TensorKernelFunction dictates its child class to override is the virtual destructor. If anywhere during the init or in the preprocess method you allocated memory on the heap or you made a process requiring a cleanup (like opening a file or making a database connection), then in the virtual destructor, it is also your responsibility to clean all them up. Also, in the constructor that has an empty implementation, we did not forget to initialize the parent class with the parameters provided to the child class constructor. To remember what these parameters refer to, you can do so by looking at tutorial 1, how to use the config file. AddingCPUTensorKernel.cpp #include \"AddingCPUTensorKernel.h\" bool AddingCPUTensorKernel::init(const SparseTensor &A) { if (// some checks may be done) { return false; } // Your initialization code goes here return true; } AddingCPUTensorKernel::~AddingCPUTensorKernel() { // Your destructor code goes here. } void AddingCPUTensorKernel::preprocess(const SparseTensor& A) { // Your preprocess code goes here. } void AddingCPUTensorKernel::functionBody(const SparseTensor& A, int iterNumber) { // Your function body code goes here. } The remaining steps to integrate the tensor kernel into SparseViz closely mirror those for adding tensor ordering. Initially, we must incorporate our class declaration and implementation into the CMakeLists.txt. Following this, we will introduce our tensor kernel definition into the SparseVizEngine, enabling the library to recognize and utilize this new kernel. CMakeLists.txt set(HEADER_FILES --- OTHER HEADER FILES (CROPPED) --- include/Kernel/Tensor/CPU/AddingCPUTensorKernel.h ) set(SOURCE_FILES --- OTHER SOURCE FILES (CROPPED) --- src/Kernel/Tensor/CPU/AddingCPUTensorKernel.cpp ) SparseVizEngine.h #include \"AddingCPUTensorKernel.h\" SparseVizEngine.cpp TensorKernelFunction *SparseVizEngine::tensorKernelFactory(const std::string &kernelName, const std::vector<int>& threadCounts, const std::string &schedulingPolicy, int chunkSize, int nRun, int nIgnore) { --- OTHER KERNEL CLASSES (CROPPED) --- else if (kernelName == \"AddingCPUTensorKernel\") { return new AddingCPUTensorKernel(kernelName, threadCounts, schedulingPolicy, chunkSize, nRun, nIgnore); } return nullptr; } Having made all of these steps, we can safely run our library with an absolute path pointing to our config file in which we indicated our new tensor kernel named AddingCPUTensorKernel under the section *TENSOR_KERNELS* to make it get executed on each ordered matrices, like so: config *TENSOR_KERNELS* AddingCPUTensorKernel | WeHaveAddedACPUTensorKernel | 1/2/4/6/8/16 | dynamic | 256 | 10 | 2 This concludes tutorial 5.1, the way to add CPU tensor kernels into the library. In tutorial 5.2, its GPU counterpart will be explained.","title":"Tutorial 5.1: How to Add CPU Tensor Kernel"},{"location":"addingGPUMatrixKernel/","text":"Tutorial 4.2: How to Add GPU Matrix Kernel In this tutorial, we will have a look at how GPU matrix kernels are added to the SparseViz library. All user-defined GPU matrix kernel classes should derive from the abstract MatrixGPUKernel class that facilitates the integration of kernels into SparseViz. As indicated previously, GPU matrix kernel parallelization is made possible with Cuda in the SparseViz library. That's why, along the way, we are going to need .cu and .cuh files in which to implement our parallel device kernels that are going to be executed on GPU. First stop, we are going to create our class declaration under the directory SparseViz/include/Kernel/Matrix/GPU. AddingGPUMatrixKernel.h #include \"MatrixGPUKernel.h\" class AddingGPUMatrixKernel: public MatrixGPUKernel { public: AddingGPUMatrixKernel(const std::string& kernelName, const std::vector<int>& gridSizes, const std::vector<int>& blockSizes, int nRun, int nIgnore) : MatrixGPUKernel(kernelName, gridSizes, blockSizes, nRun, nIgnore) {} virtual ~AddingGPUMatrixKernel() override; virtual bool init(const SparseMatrix& A); virtual void preprocess(const SparseMatrix& A) {} virtual void hostFunction(const SparseMatrix& A, int iterNumber, int gridSize, int blockSize); }; It is almost the same declaration as Matrix CPU kernel except that the functionBody name has been changed with hostFunction and it takes additional 2 parameters indicating the gridSize and the blockSize of the current iteration. Now it is time for the implementation file, which we will create under the directory SparseViz/src/Kernel/Matrix/GPU. AddingGPUMatrixKernel.cu #include \"AddingGPUMatrixKernel.h\" #include \"GPUKernels.cuh\" #include \"cuda_runtime.h\" bool AddingGPUMatrixKernel::init(const SparseMatrix &A) { if (// some checks may be done) { return false; } // Your initialization code goes here return true; } AddingGPUMatrixKernel::~AddingGPUMatrixKernel() { // Your destructor code goes here } void AddingGPUMatrixKernel::hostFunction(const SparseMatrix &A, int iterNumber, int gridSize, int blockSize) { // Your host function code goes here, including Cuda memcpy and malloc statements. GPUMatrixKernel<<<gridSize, blockSize>>>(// Your gpu kernel parameters goes here); // Your host function code continues from there, including Cuda memcpy and free statements. } Some parts require details in the above source code. First, it is important to realize that the file does not have a normal cpp source code extension but has a .cu extension that requires compilation to be done by the nvcc compiler. As a second remark, there is an additional include from which GPUMatrixKernel declaration is received. Users may include their device kernel declarations into SparseViz/include/Kernel/GPUKernels.cuh file. From there, the appropriate device kernel can be called as shown by the hostFunction which we have completed its implementation of. Device kernel declaration is done under GPUKernels.cuh cuda header file looks like the following: GPUKernels.cuh --- OTHER DEVICE KERNEL DECLARATIONS (CROPPED) --- __global__ void GPUMatrixKernel(// Your device kernel parameters goes here); Similarly, its implementation could be done in the SparseViz/src/Kernel/GPUKernels.cu file that looks like the following: GPUKernels.cu __global__ void GPUMatrixKernel(// Your device kernel parameters goes here) { // Your device kernel implementation goes here } Having made all necessary declarations and implementations both for our host and device functions, we can proceed to add them into CMakeLists.txt. Because .cu files are compiled only when Cuda and Cuda-capable GPU are installed, we are going to add the files into CMakeLists.txt conditionally, like so: CMakeLists.txt include(CheckLanguage) check_language(CUDA) if(CMAKE_CUDA_COMPILER) enable_language(CUDA) add_definitions(-DCUDA_ENABLED) --- OTHER HEADER FILE APPEND STATEMENTS (CROPPED) --- list(APPEND HEADER_FILES include/Kernel/Matrix/GPU/AddingGPUMatrixKernel.h) --- OTHER SOURCE FILE APPEND STATEMENTS (CROPPED) --- list(APPEND SOURCE_FILES src/Kernel/Matrix/GPU/AddingGPUMatrixKernel.cu) endif() As a final step, we will introduce our matrix GPU kernel definition into the SparseVizEngine, enabling the library to recognize and utilize this new kernel. The only part to pay attention to is that every code that we are going to include should be within a conditional macro named CUDA_ENABLED. SparseVizEngine.h #ifdef CUDA_ENABLED --- OTHER GPU KERNEL INCLUDES (CROPPED) --- #include \"AddingGPUMatrixKernel.h\" #endif SparseVizEngine.cpp #ifdef CUDA_ENABLED MatrixGPUKernel *SparseVizEngine::matrixGPUKernelFactory(const std::string &kernelName, const std::vector<int> &gridSizes, const std::vector<int> &blockSizes, int nRun, int nIgnore) { --- OTHER GPU KERNEL CLASSES (CROPPED) --- else if (kernelName == \"AddingGPUMatrixKernel\") { return new AddingGPUMatrixKernel(kernelName, gridSizes, blockSizes, nRun, nIgnore); } return nullptr; } #endif Finally, we can run or GPU matrix kernel from the config file by indicating it under the section named *GPU_MATRIX_KERNELS*, as follows: config *GPU_MATRIX_KERNELS* AddingGPUMatrixKernel | 4 | 256 | 10 | 2 This concludes tutorial 4.2, adding GPU matrix kernel into the SparseViz library.","title":"Adding GPU Matrix Kernel"},{"location":"addingGPUMatrixKernel/#tutorial-42-how-to-add-gpu-matrix-kernel","text":"In this tutorial, we will have a look at how GPU matrix kernels are added to the SparseViz library. All user-defined GPU matrix kernel classes should derive from the abstract MatrixGPUKernel class that facilitates the integration of kernels into SparseViz. As indicated previously, GPU matrix kernel parallelization is made possible with Cuda in the SparseViz library. That's why, along the way, we are going to need .cu and .cuh files in which to implement our parallel device kernels that are going to be executed on GPU. First stop, we are going to create our class declaration under the directory SparseViz/include/Kernel/Matrix/GPU. AddingGPUMatrixKernel.h #include \"MatrixGPUKernel.h\" class AddingGPUMatrixKernel: public MatrixGPUKernel { public: AddingGPUMatrixKernel(const std::string& kernelName, const std::vector<int>& gridSizes, const std::vector<int>& blockSizes, int nRun, int nIgnore) : MatrixGPUKernel(kernelName, gridSizes, blockSizes, nRun, nIgnore) {} virtual ~AddingGPUMatrixKernel() override; virtual bool init(const SparseMatrix& A); virtual void preprocess(const SparseMatrix& A) {} virtual void hostFunction(const SparseMatrix& A, int iterNumber, int gridSize, int blockSize); }; It is almost the same declaration as Matrix CPU kernel except that the functionBody name has been changed with hostFunction and it takes additional 2 parameters indicating the gridSize and the blockSize of the current iteration. Now it is time for the implementation file, which we will create under the directory SparseViz/src/Kernel/Matrix/GPU. AddingGPUMatrixKernel.cu #include \"AddingGPUMatrixKernel.h\" #include \"GPUKernels.cuh\" #include \"cuda_runtime.h\" bool AddingGPUMatrixKernel::init(const SparseMatrix &A) { if (// some checks may be done) { return false; } // Your initialization code goes here return true; } AddingGPUMatrixKernel::~AddingGPUMatrixKernel() { // Your destructor code goes here } void AddingGPUMatrixKernel::hostFunction(const SparseMatrix &A, int iterNumber, int gridSize, int blockSize) { // Your host function code goes here, including Cuda memcpy and malloc statements. GPUMatrixKernel<<<gridSize, blockSize>>>(// Your gpu kernel parameters goes here); // Your host function code continues from there, including Cuda memcpy and free statements. } Some parts require details in the above source code. First, it is important to realize that the file does not have a normal cpp source code extension but has a .cu extension that requires compilation to be done by the nvcc compiler. As a second remark, there is an additional include from which GPUMatrixKernel declaration is received. Users may include their device kernel declarations into SparseViz/include/Kernel/GPUKernels.cuh file. From there, the appropriate device kernel can be called as shown by the hostFunction which we have completed its implementation of. Device kernel declaration is done under GPUKernels.cuh cuda header file looks like the following: GPUKernels.cuh --- OTHER DEVICE KERNEL DECLARATIONS (CROPPED) --- __global__ void GPUMatrixKernel(// Your device kernel parameters goes here); Similarly, its implementation could be done in the SparseViz/src/Kernel/GPUKernels.cu file that looks like the following: GPUKernels.cu __global__ void GPUMatrixKernel(// Your device kernel parameters goes here) { // Your device kernel implementation goes here } Having made all necessary declarations and implementations both for our host and device functions, we can proceed to add them into CMakeLists.txt. Because .cu files are compiled only when Cuda and Cuda-capable GPU are installed, we are going to add the files into CMakeLists.txt conditionally, like so: CMakeLists.txt include(CheckLanguage) check_language(CUDA) if(CMAKE_CUDA_COMPILER) enable_language(CUDA) add_definitions(-DCUDA_ENABLED) --- OTHER HEADER FILE APPEND STATEMENTS (CROPPED) --- list(APPEND HEADER_FILES include/Kernel/Matrix/GPU/AddingGPUMatrixKernel.h) --- OTHER SOURCE FILE APPEND STATEMENTS (CROPPED) --- list(APPEND SOURCE_FILES src/Kernel/Matrix/GPU/AddingGPUMatrixKernel.cu) endif() As a final step, we will introduce our matrix GPU kernel definition into the SparseVizEngine, enabling the library to recognize and utilize this new kernel. The only part to pay attention to is that every code that we are going to include should be within a conditional macro named CUDA_ENABLED. SparseVizEngine.h #ifdef CUDA_ENABLED --- OTHER GPU KERNEL INCLUDES (CROPPED) --- #include \"AddingGPUMatrixKernel.h\" #endif SparseVizEngine.cpp #ifdef CUDA_ENABLED MatrixGPUKernel *SparseVizEngine::matrixGPUKernelFactory(const std::string &kernelName, const std::vector<int> &gridSizes, const std::vector<int> &blockSizes, int nRun, int nIgnore) { --- OTHER GPU KERNEL CLASSES (CROPPED) --- else if (kernelName == \"AddingGPUMatrixKernel\") { return new AddingGPUMatrixKernel(kernelName, gridSizes, blockSizes, nRun, nIgnore); } return nullptr; } #endif Finally, we can run or GPU matrix kernel from the config file by indicating it under the section named *GPU_MATRIX_KERNELS*, as follows: config *GPU_MATRIX_KERNELS* AddingGPUMatrixKernel | 4 | 256 | 10 | 2 This concludes tutorial 4.2, adding GPU matrix kernel into the SparseViz library.","title":"Tutorial 4.2: How to Add GPU Matrix Kernel"},{"location":"addingGPUTensorKernel/","text":"Tutorial 5.2: How to Add GPU Tensor Kernel In this tutorial, we will have a look at how GPU tensor kernels are added to the SparseViz library. All user-defined GPU tensor kernel classes should derive from the abstract TensorGPUKernel class that facilitates the integration of kernels into SparseViz. As indicated previously, GPU tensor kernel parallelization is made possible with Cuda in the SparseViz library. That's why, along the way, we are going to need .cu and .cuh files in which to implement our parallel device kernels that are going to be executed on GPU. First stop, we are going to create our class declaration under the directory SparseViz/include/Kernel/Tensor/GPU. AddingGPUTensorKernel.h #include \"TensorGPUKernel.h\" class AddingGPUTensorKernel: public TensorGPUKernel { public: AddingGPUTensorKernel(const std::string& kernelName, const std::vector<int>& gridSizes, const std::vector<int>& blockSizes, int nRun, int nIgnore) : TensorGPUKernel(kernelName, gridSizes, blockSizes, nRun, nIgnore) {} virtual ~AddingGPUTensorKernel() override; virtual bool init(const SparseTensor& A); virtual void preprocess(const SparseTensor& A) {} virtual void hostFunction(const SparseTensor& A, int iterNumber, int gridSize, int blockSize); }; It is almost the same declaration as the Tensor CPU kernel except that the functionBody name has been changed with hostFunction and it takes additional 2 parameters indicating the gridSize and the blockSize of the current iteration. Now it is time for the implementation file, which we will create under the directory SparseViz/src/Kernel/Tensor/GPU. AddingGPUTensorKernel.cu #include \"AddingGPUTensorKernel.h\" #include \"GPUKernels.cuh\" #include \"cuda_runtime.h\" bool AddingGPUTensorKernel::init(const SparseTensor &A) { if (// some checks may be done) { return false; } // Your initialization code goes here return true; } AddingGPUTensorKernel::~AddingGPUTensorKernel() { // Your destructor code goes here } void AddingGPUTensorKernel::hostFunction(const SparseTensor &A, int iterNumber, int gridSize, int blockSize) { // Your host function code goes here, including Cuda memcpy and malloc statements. GPUTensorKernel<<<gridSize, blockSize>>>(// Your gpu kernel parameters goes here); // Your host function code continues from there, including Cuda memcpy and free statements. } Some parts require details in the above source code. First, it is important to realize that the file does not have a normal cpp source code extension but has a .cu extension that requires compilation to be done by the nvcc compiler. As a second remark, there is an additional include from which GPUTensorKernel declaration is received. Users may include their device kernel declarations into SparseViz/include/Kernel/GPUKernels.cuh file. From there, the appropriate device kernel can be called as shown by the hostFunction which we have completed its implementation of. Device kernel declaration is done under GPUKernels.cuh cuda header file looks like the following: GPUKernels.cuh --- OTHER DEVICE KERNEL DECLARATIONS (CROPPED) --- __global__ void GPUTensorKernel(// Your device kernel parameters goes here); Similarly, its implementation could be done in the SparseViz/src/Kernel/GPUKernels.cu file that looks like the following: GPUKernels.cu __global__ void GPUTensorKernel(// Your device kernel parameters goes here) { // Your device kernel implementation goes here } Having made all necessary declarations and implementations both for our host and device functions, we can proceed to add them into CMakeLists.txt. Because .cu files are compiled only when Cuda and Cuda-capable GPU are installed, we are going to add the files into CMakeLists.txt conditionally, like so: CMakeLists.txt include(CheckLanguage) check_language(CUDA) if(CMAKE_CUDA_COMPILER) enable_language(CUDA) add_definitions(-DCUDA_ENABLED) --- OTHER HEADER FILE APPEND STATEMENTS (CROPPED) --- list(APPEND HEADER_FILES include/Kernel/Tensor/GPU/AddingGPUTensorKernel.h) --- OTHER SOURCE FILE APPEND STATEMENTS (CROPPED) --- list(APPEND SOURCE_FILES src/Kernel/Tensor/GPU/AddingGPUTensorKernel.cu) endif() As a final step, we will introduce our tensor GPU kernel definition into the SparseVizEngine, enabling the library to recognize and utilize this new kernel. The only part to pay attention to is that every code that we are going to include should be within a conditional macro named CUDA_ENABLED. SparseVizEngine.h #ifdef CUDA_ENABLED --- OTHER GPU KERNEL INCLUDES (CROPPED) --- #include \"AddingGPUTensorKernel.h\" #endif SparseVizEngine.cpp #ifdef CUDA_ENABLED TensorGPUKernel *SparseVizEngine::tensorGPUKernelFactory(const std::string &kernelName, const std::vector<int> &gridSizes, const std::vector<int> &blockSizes, int nRun, int nIgnore) { --- OTHER GPU KERNEL CLASSES (CROPPED) --- else if (kernelName == \"AddingGPUTensorKernel\") { return new AddingGPUTensorKernel(kernelName, gridSizes, blockSizes, nRun, nIgnore); } return nullptr; } #endif Finally, we can run or GPU tensor kernel from the config file by indicating it under the section named *GPU_TENSOR_KERNELS*, as follows: config *GPU_TENSOR_KERNELS* AddingGPUTensorKernel | 4 | 256 | 10 | 2 This concludes tutorial 5.2, adding gpu tensor kernel into the SparseViz library.","title":"Adding GPU Tensor Kernel"},{"location":"addingGPUTensorKernel/#tutorial-52-how-to-add-gpu-tensor-kernel","text":"In this tutorial, we will have a look at how GPU tensor kernels are added to the SparseViz library. All user-defined GPU tensor kernel classes should derive from the abstract TensorGPUKernel class that facilitates the integration of kernels into SparseViz. As indicated previously, GPU tensor kernel parallelization is made possible with Cuda in the SparseViz library. That's why, along the way, we are going to need .cu and .cuh files in which to implement our parallel device kernels that are going to be executed on GPU. First stop, we are going to create our class declaration under the directory SparseViz/include/Kernel/Tensor/GPU. AddingGPUTensorKernel.h #include \"TensorGPUKernel.h\" class AddingGPUTensorKernel: public TensorGPUKernel { public: AddingGPUTensorKernel(const std::string& kernelName, const std::vector<int>& gridSizes, const std::vector<int>& blockSizes, int nRun, int nIgnore) : TensorGPUKernel(kernelName, gridSizes, blockSizes, nRun, nIgnore) {} virtual ~AddingGPUTensorKernel() override; virtual bool init(const SparseTensor& A); virtual void preprocess(const SparseTensor& A) {} virtual void hostFunction(const SparseTensor& A, int iterNumber, int gridSize, int blockSize); }; It is almost the same declaration as the Tensor CPU kernel except that the functionBody name has been changed with hostFunction and it takes additional 2 parameters indicating the gridSize and the blockSize of the current iteration. Now it is time for the implementation file, which we will create under the directory SparseViz/src/Kernel/Tensor/GPU. AddingGPUTensorKernel.cu #include \"AddingGPUTensorKernel.h\" #include \"GPUKernels.cuh\" #include \"cuda_runtime.h\" bool AddingGPUTensorKernel::init(const SparseTensor &A) { if (// some checks may be done) { return false; } // Your initialization code goes here return true; } AddingGPUTensorKernel::~AddingGPUTensorKernel() { // Your destructor code goes here } void AddingGPUTensorKernel::hostFunction(const SparseTensor &A, int iterNumber, int gridSize, int blockSize) { // Your host function code goes here, including Cuda memcpy and malloc statements. GPUTensorKernel<<<gridSize, blockSize>>>(// Your gpu kernel parameters goes here); // Your host function code continues from there, including Cuda memcpy and free statements. } Some parts require details in the above source code. First, it is important to realize that the file does not have a normal cpp source code extension but has a .cu extension that requires compilation to be done by the nvcc compiler. As a second remark, there is an additional include from which GPUTensorKernel declaration is received. Users may include their device kernel declarations into SparseViz/include/Kernel/GPUKernels.cuh file. From there, the appropriate device kernel can be called as shown by the hostFunction which we have completed its implementation of. Device kernel declaration is done under GPUKernels.cuh cuda header file looks like the following: GPUKernels.cuh --- OTHER DEVICE KERNEL DECLARATIONS (CROPPED) --- __global__ void GPUTensorKernel(// Your device kernel parameters goes here); Similarly, its implementation could be done in the SparseViz/src/Kernel/GPUKernels.cu file that looks like the following: GPUKernels.cu __global__ void GPUTensorKernel(// Your device kernel parameters goes here) { // Your device kernel implementation goes here } Having made all necessary declarations and implementations both for our host and device functions, we can proceed to add them into CMakeLists.txt. Because .cu files are compiled only when Cuda and Cuda-capable GPU are installed, we are going to add the files into CMakeLists.txt conditionally, like so: CMakeLists.txt include(CheckLanguage) check_language(CUDA) if(CMAKE_CUDA_COMPILER) enable_language(CUDA) add_definitions(-DCUDA_ENABLED) --- OTHER HEADER FILE APPEND STATEMENTS (CROPPED) --- list(APPEND HEADER_FILES include/Kernel/Tensor/GPU/AddingGPUTensorKernel.h) --- OTHER SOURCE FILE APPEND STATEMENTS (CROPPED) --- list(APPEND SOURCE_FILES src/Kernel/Tensor/GPU/AddingGPUTensorKernel.cu) endif() As a final step, we will introduce our tensor GPU kernel definition into the SparseVizEngine, enabling the library to recognize and utilize this new kernel. The only part to pay attention to is that every code that we are going to include should be within a conditional macro named CUDA_ENABLED. SparseVizEngine.h #ifdef CUDA_ENABLED --- OTHER GPU KERNEL INCLUDES (CROPPED) --- #include \"AddingGPUTensorKernel.h\" #endif SparseVizEngine.cpp #ifdef CUDA_ENABLED TensorGPUKernel *SparseVizEngine::tensorGPUKernelFactory(const std::string &kernelName, const std::vector<int> &gridSizes, const std::vector<int> &blockSizes, int nRun, int nIgnore) { --- OTHER GPU KERNEL CLASSES (CROPPED) --- else if (kernelName == \"AddingGPUTensorKernel\") { return new AddingGPUTensorKernel(kernelName, gridSizes, blockSizes, nRun, nIgnore); } return nullptr; } #endif Finally, we can run or GPU tensor kernel from the config file by indicating it under the section named *GPU_TENSOR_KERNELS*, as follows: config *GPU_TENSOR_KERNELS* AddingGPUTensorKernel | 4 | 256 | 10 | 2 This concludes tutorial 5.2, adding gpu tensor kernel into the SparseViz library.","title":"Tutorial 5.2: How to Add GPU Tensor Kernel"},{"location":"addingMatrixOrdering/","text":"Tutorial 2: How to Add Matrix Ordering SparseViz allows its users to add the custom matrix orderings that they want to implement on their matrices. Adding such matrix orderings into SparseViz involves a couple of elementary steps. In this tutorial, these steps are going to be explained in a detailed manner. Every custom matrix ordering in the SparseViz ecosystem derives from the abstract MatrixOrdering class. SparseViz/include/Matrix/Orderings is where the header file of this custom ordering class could be created and SparseViz/src/Matrix/Orderings is where the source file of this custom ordering class could be created. In this tutorial, we are going to create an example matrix ordering named AddingMatrixOrdering and show how it can be integrated into the library. Step 1: Creating a Custom Ordering Class First, we will create the AddingMatrixOrdering.h file in the SparseViz/include/Matrix/Orderings directory. The header file will contain the declaration of our class, which consists of only 5 lines of C++ code. AddingMatrixOrdering.h #include \"MatrixOrdering\" class AddingMatrixOrdering: public MatrixOrdering { public: AddingMatrixOrdering(SparseMatrix& matrix, std::string orderingName, std::string orderingParameters); virtual void orderingFunction() override; }; MatrixOrdering has only one pure virtual function that it dictates to be overridden by every derived class. This function is called orderingFunction which would carry the implementation of the ordering logic. In addition to that, a constructor should be written for the custom matrix ordering classes whose first 2 parameters have to be the reference to the matrix on which the ordering will be applied and the name of the ordering, respectively. The third parameter is optional in that it can be skipped safely if the custom order does not need any parameters to work properly. Having declared our class, next is to create its source file named AddingMatrixOrdering.cpp under the directory SparseViz/src/Matrix/Orderings. AddingMatrixOrdering.cpp #include \"AddingMatrixOrdering.h\" AddingMatrixOrdering::AddingMatrixOrdering(SparseMatrix &matrix, std::string orderingName, std::string orderingParameters) : MatrixOrdering(matrix, orderingName, true, true, 5) { // Ordering parameters could be parsed (remember the delimiter is '/') // and appropriate private member variables could be set here } void AddingMatrixOrdering::orderingFunction() { rowIPermutation = new vType[this->getMatrix().getRowCount()]; colIPermutation = new vType[this->getMatrix().getColCount()]; // Your ordering function logic goes here } There are a couple of important parts in the source code that require careful attention. The first is the initialization of the base class MatrixOrdering in the constructor of the AddingMatrixOrdering class. MatrixOrdering expects the following parameters to be provided. SparseMatrix& matrix std::string orderingName bool rectangularSupport bool patternUnsymmetricSupport unsigned int orderingFunctionPrice = 0 The first 2 parameters, matrix, and orderingName, could easily be provided to the parent class with the constructor parameters of the child class. The third parameter, rectangularSupport, determines whether or not this custom ordering class has support for rectangular matrices. In case a rectangular matrix will be tried to be ordered in a scenario in which this support is not found, then MatrixOrdering will create an ordering-supported matrix during the runtime to make this ordering possible. Similar to the rectangular support parameter, the patternUnsymmetricSupport parameter determines whether or not this custom ordering class has support for matrices in which pattern symmetry is not available. In case a pattern unsymmetric matrix will be tried to be ordered in a scenario in which this support is not found, an ordering support matrix will be created in the runtime by the MatrixOrdering library to make this ordering possible. The last parameter is an integer between 0 to 10 representing the overhead of the ordering function. Although it has a default value of 0, we recommend custom ordering derived classes to specify this value, as appropriate values could increase the performance of the program. For our ordering class, we will assume that it supports rectangular and pattern unsymmetric matrices with an orderingFunction overhead value of 5. The last important remark that we need to make is that in the custom matrix orderings, 2 arrays should be generated by orderingFunction. These are the only protected member variables of the MatrixOrdering base class whose initialization values are nullptr. These arrays are called rowIPermutation and colIPermutation which determine the new location of each row and column after the ordering is implemented. They should be allocated on the heap with sizes equal to the row size for rowIPermutation and equal to the col size of colIPermutation. Custom ordering classes are not responsible for deleting these arrays, as the MatrixOrdering base class will safely handle this problem. Step 2: Adding Files into CMakeLists.txt In the former step, we have created our header file and source file for our class named AddingMatrixOrdering. In this step, we are going to include these files in our build automation tool. SparseViz utilizes CMake as its build system. In the CMakeLists.txt file located under the project directory, we should include our header file under the HEADER_FILES environment variable and include our source under the SOURCE_FILES environment variable, like so: CMakeLists.txt set(HEADER_FILES --- OTHER HEADER FILES (CROPPED) --- include/Matrix/Orderings/AddingMatrixOrdering.h ) set(SOURCE_FILES --- OTHER SOURCE FILES (CROPPED) --- src/Matrix/Orderings/AddingMatrixOrdering.cpp ) Step 3: Adding Ordering Definition Into SparseVizEngine As the last step, we are going to add our ordering class definition into SparseVizEngine and allow the library to identify the presence of this ordering. As our first job, we are going to include our custom ordering class' header file into the SparseVizEngine.h: SparseVizEngine.h #include \"AddingMatrixOrdering.h\" After that, we are going to add the definition of the class to the matrix ordering factory function located in the source file of the SparseVizEngine SparseVizEngine.cpp MatrixOrdering *SparseVizEngine::matrixOrderingFactory(SparseMatrix& matrix, std::string orderingClassName, std::string orderingName, std::string orderingParameters) { --- OTHER ORDERING CLASSES (CROPPED) --- else if (orderingClassName == \"AddingMatrixOrdering\") { return new AddingMatrixOrdering(matrix, orderingName, orderingParameters); } return nullptr; } Having done this, we can easily run this ordering from within the config file by indicating it under the section *MATRIX_ORDERINGS*, like so: config *MATRIX_ORDERINGS* AddingMatrixOrdering | WeHaveAddedAMatrixOrdering | Param1/Param2/Param3 This concludes the tutorial 2, the way to add matrix orderings into the library.","title":"Adding Matrix Ordering"},{"location":"addingMatrixOrdering/#tutorial-2-how-to-add-matrix-ordering","text":"SparseViz allows its users to add the custom matrix orderings that they want to implement on their matrices. Adding such matrix orderings into SparseViz involves a couple of elementary steps. In this tutorial, these steps are going to be explained in a detailed manner. Every custom matrix ordering in the SparseViz ecosystem derives from the abstract MatrixOrdering class. SparseViz/include/Matrix/Orderings is where the header file of this custom ordering class could be created and SparseViz/src/Matrix/Orderings is where the source file of this custom ordering class could be created. In this tutorial, we are going to create an example matrix ordering named AddingMatrixOrdering and show how it can be integrated into the library.","title":"Tutorial 2: How to Add Matrix Ordering"},{"location":"addingMatrixOrdering/#step-1-creating-a-custom-ordering-class","text":"First, we will create the AddingMatrixOrdering.h file in the SparseViz/include/Matrix/Orderings directory. The header file will contain the declaration of our class, which consists of only 5 lines of C++ code. AddingMatrixOrdering.h #include \"MatrixOrdering\" class AddingMatrixOrdering: public MatrixOrdering { public: AddingMatrixOrdering(SparseMatrix& matrix, std::string orderingName, std::string orderingParameters); virtual void orderingFunction() override; }; MatrixOrdering has only one pure virtual function that it dictates to be overridden by every derived class. This function is called orderingFunction which would carry the implementation of the ordering logic. In addition to that, a constructor should be written for the custom matrix ordering classes whose first 2 parameters have to be the reference to the matrix on which the ordering will be applied and the name of the ordering, respectively. The third parameter is optional in that it can be skipped safely if the custom order does not need any parameters to work properly. Having declared our class, next is to create its source file named AddingMatrixOrdering.cpp under the directory SparseViz/src/Matrix/Orderings. AddingMatrixOrdering.cpp #include \"AddingMatrixOrdering.h\" AddingMatrixOrdering::AddingMatrixOrdering(SparseMatrix &matrix, std::string orderingName, std::string orderingParameters) : MatrixOrdering(matrix, orderingName, true, true, 5) { // Ordering parameters could be parsed (remember the delimiter is '/') // and appropriate private member variables could be set here } void AddingMatrixOrdering::orderingFunction() { rowIPermutation = new vType[this->getMatrix().getRowCount()]; colIPermutation = new vType[this->getMatrix().getColCount()]; // Your ordering function logic goes here } There are a couple of important parts in the source code that require careful attention. The first is the initialization of the base class MatrixOrdering in the constructor of the AddingMatrixOrdering class. MatrixOrdering expects the following parameters to be provided. SparseMatrix& matrix std::string orderingName bool rectangularSupport bool patternUnsymmetricSupport unsigned int orderingFunctionPrice = 0 The first 2 parameters, matrix, and orderingName, could easily be provided to the parent class with the constructor parameters of the child class. The third parameter, rectangularSupport, determines whether or not this custom ordering class has support for rectangular matrices. In case a rectangular matrix will be tried to be ordered in a scenario in which this support is not found, then MatrixOrdering will create an ordering-supported matrix during the runtime to make this ordering possible. Similar to the rectangular support parameter, the patternUnsymmetricSupport parameter determines whether or not this custom ordering class has support for matrices in which pattern symmetry is not available. In case a pattern unsymmetric matrix will be tried to be ordered in a scenario in which this support is not found, an ordering support matrix will be created in the runtime by the MatrixOrdering library to make this ordering possible. The last parameter is an integer between 0 to 10 representing the overhead of the ordering function. Although it has a default value of 0, we recommend custom ordering derived classes to specify this value, as appropriate values could increase the performance of the program. For our ordering class, we will assume that it supports rectangular and pattern unsymmetric matrices with an orderingFunction overhead value of 5. The last important remark that we need to make is that in the custom matrix orderings, 2 arrays should be generated by orderingFunction. These are the only protected member variables of the MatrixOrdering base class whose initialization values are nullptr. These arrays are called rowIPermutation and colIPermutation which determine the new location of each row and column after the ordering is implemented. They should be allocated on the heap with sizes equal to the row size for rowIPermutation and equal to the col size of colIPermutation. Custom ordering classes are not responsible for deleting these arrays, as the MatrixOrdering base class will safely handle this problem.","title":"Step 1: Creating a Custom Ordering Class"},{"location":"addingMatrixOrdering/#step-2-adding-files-into-cmakeliststxt","text":"In the former step, we have created our header file and source file for our class named AddingMatrixOrdering. In this step, we are going to include these files in our build automation tool. SparseViz utilizes CMake as its build system. In the CMakeLists.txt file located under the project directory, we should include our header file under the HEADER_FILES environment variable and include our source under the SOURCE_FILES environment variable, like so: CMakeLists.txt set(HEADER_FILES --- OTHER HEADER FILES (CROPPED) --- include/Matrix/Orderings/AddingMatrixOrdering.h ) set(SOURCE_FILES --- OTHER SOURCE FILES (CROPPED) --- src/Matrix/Orderings/AddingMatrixOrdering.cpp )","title":"Step 2: Adding Files into CMakeLists.txt"},{"location":"addingMatrixOrdering/#step-3-adding-ordering-definition-into-sparsevizengine","text":"As the last step, we are going to add our ordering class definition into SparseVizEngine and allow the library to identify the presence of this ordering. As our first job, we are going to include our custom ordering class' header file into the SparseVizEngine.h: SparseVizEngine.h #include \"AddingMatrixOrdering.h\" After that, we are going to add the definition of the class to the matrix ordering factory function located in the source file of the SparseVizEngine SparseVizEngine.cpp MatrixOrdering *SparseVizEngine::matrixOrderingFactory(SparseMatrix& matrix, std::string orderingClassName, std::string orderingName, std::string orderingParameters) { --- OTHER ORDERING CLASSES (CROPPED) --- else if (orderingClassName == \"AddingMatrixOrdering\") { return new AddingMatrixOrdering(matrix, orderingName, orderingParameters); } return nullptr; } Having done this, we can easily run this ordering from within the config file by indicating it under the section *MATRIX_ORDERINGS*, like so: config *MATRIX_ORDERINGS* AddingMatrixOrdering | WeHaveAddedAMatrixOrdering | Param1/Param2/Param3 This concludes the tutorial 2, the way to add matrix orderings into the library.","title":"Step 3: Adding Ordering Definition Into SparseVizEngine"},{"location":"addingTensorOrdering/","text":"Tutorial 3: How to Add Tensor Ordering SparseViz allows its users to add the custom tensor orderings that they want to implement on their tensors. Adding such tensor orderings into SparseViz involves a couple of elementary steps. In this tutorial, these steps are going to be explained in a detailed manner. Every custom tensor ordering in the SparseViz ecosystem derives from the abstract TensorOrdering class. SparseViz/include/Tensor/Orderings is where the header file of this custom ordering class could be created and SparseViz/src/Tensor/Orderings is where the source file of this custom ordering class could be created. In this tutorial, we are going to create an example tensor ordering named AddingTensorOrdering and show how it can be integrated into the library. Step 1: Creating a Custom Ordering Class First, we will create the AddingTensorOrdering.h file in the SparseViz/include/Tensor/Orderings directory. The header file will contain the declaration of our class, which consists of only 5 lines of C++ code. AddingTensorOrdering.h #include \"TensorOrdering.h\" class AddingTensorOrdering: public TensorOrdering { public: AddingTensorOrdering (SparseTensor& tensor, const std::vector\\<vType\\>& active_modes, std::string orderingName, std::string orderingParameters); virtual void orderingFunction() override; }; TensorOrdering has only one pure virtual function that it dictates to be overridden by every derived class. This function is called orderingFunction which would carry the implementation of the ordering logic. In addition to that, a constructor should be written for the custom tensor ordering classes whose first 3 parameters have to be the reference to the tensor on which the ordering will be applied, the active modes of the tensor, and the name of the ordering, respectively. The fourth parameter is optional in that it can be skipped safely if the custom order does not need any parameters to work properly. Having declared our class, next is to create its source file named AddingTensorOrdering.cpp under the directory SparseViz/src/Tensor/Orderings. AddingTensorOrdering.cpp #include \"AddingTensorOrdering.h\" AddingTensorOrdering:: AddingTensorOrdering (SparseTensor &tensor, const std::vector<vType>& active_modes, std::string orderingName, std::string orderingParameters) : TensorOrdering(tensor, active_modes, orderingName, 5) { // Ordering parameters could be parsed (remember the delimiter is '/') // and appropriate private member variables could be set here } void AddingTensorOrdering::orderingFunction() { vType tensorOrder = this->getTensor().getOrder(); orderedDimensions = new vType*[tensorOrder]; for (int i = 0; i != tensorOrder; ++i) { orderedDimensions[i] = new vType[dims[i]]; } // Your ordering function logic goes here } There are a couple of important parts in the source code that require careful attention. The first is the initialization of the base class TensorOrdering in the constructor of the AddingTensorOrdering class. TensorOrdering expects the following parameters to be provided. SparseTensor& tensor const std::vector & active_modes std::string orderingName unsigned int orderingFunctionPrice = 0 The first 3 parameters, matrix, active_modes, and orderingName, could easily be provided to the parent class with the constructor parameters of the child class. The last parameter is an integer between 0 to 10 representing the overhead of the ordering function. Although it has a default value of 0, we recommend custom ordering derived classes to specify this value, as appropriate values could increase the performance of the program. For our ordering class, we will assume that it has an orderingFunction overhead value of 5. The last important remark that we need to make is that in the custom tensor orderings, a matrix should be generated by the orderingFunction. This matrix is a protected member variable of TensorOrdering called orderedDimensions that would keep track of the new locations of each dimension after the ordering is implemented. This matrix should be allocated on the heap as shown in the above code snippet. The custom tensor ordering class is not responsible for deleting this matrix, as the base TensorOrdering class will safely handle this. Step 2: Adding Files into CMakeLists.txt In the former step, we created our header file and source file for our class named AddingTensorOrdering. In this step, we are going to include these files in our build automation tool. SparseViz utilizes CMake as its build system. In the CMakeLists.txt file located under the project directory, we should include our header file under the HEADER_FILES environment variable and include our source under the SOURCE_FILES environment variable, like so: CMakeLists.txt set(HEADER_FILES --- OTHER HEADER FILES (CROPPED) --- include/Tensor/Orderings/AddingTensorOrdering.h ) set(SOURCE_FILES --- OTHER SOURCE FILES (CROPPED) --- src/Tensor/Orderings/AddingTensorOrdering.cpp ) Step 3: Adding Ordering Definition Into SparseVizEngine As the last step, we are going to add our ordering class definition into SparseVizEngine and allow the library to identify the presence of this ordering. As our first job, we are going to include our custom ordering class' header file into the SparseVizEngine.h: SparseVizEngine.h #include \"AddingTensorOrdering.h\" After that, we are going to add the definition of the class to the tensor ordering factory function located in the source file of the SparseVizEngine SparseVizEngine.cpp TensorOrdering *SparseVizEngine::tensorOrderingFactory(SparseTensor&tensor, const std::vector<vType>& active_modes, std::string orderingClassName, std::string orderingName, std::string orderingParameters) { --- OTHER ORDERING CLASSES (CROPPED) --- else if (orderingClassName == \"AddingTensorOrdering\") { return new AddingTensorOrdering(tensor, active_modes, orderingName, orderingParameters); } return nullptr; } Having done this, we can easily run this ordering from within the config file by indicating it under the section *TENSOR_ORDERINGS*, like so: config *TENSOR_ORDERINGS* AddingTensorOrdering | WeHaveAddedATensorOrdering | Param1/Param2/Param3 This concludes tutorial 3, the way to add tensor orderings into the library.","title":"Adding Tensor Ordering"},{"location":"addingTensorOrdering/#tutorial-3-how-to-add-tensor-ordering","text":"SparseViz allows its users to add the custom tensor orderings that they want to implement on their tensors. Adding such tensor orderings into SparseViz involves a couple of elementary steps. In this tutorial, these steps are going to be explained in a detailed manner. Every custom tensor ordering in the SparseViz ecosystem derives from the abstract TensorOrdering class. SparseViz/include/Tensor/Orderings is where the header file of this custom ordering class could be created and SparseViz/src/Tensor/Orderings is where the source file of this custom ordering class could be created. In this tutorial, we are going to create an example tensor ordering named AddingTensorOrdering and show how it can be integrated into the library.","title":"Tutorial 3: How to Add Tensor Ordering"},{"location":"addingTensorOrdering/#step-1-creating-a-custom-ordering-class","text":"First, we will create the AddingTensorOrdering.h file in the SparseViz/include/Tensor/Orderings directory. The header file will contain the declaration of our class, which consists of only 5 lines of C++ code. AddingTensorOrdering.h #include \"TensorOrdering.h\" class AddingTensorOrdering: public TensorOrdering { public: AddingTensorOrdering (SparseTensor& tensor, const std::vector\\<vType\\>& active_modes, std::string orderingName, std::string orderingParameters); virtual void orderingFunction() override; }; TensorOrdering has only one pure virtual function that it dictates to be overridden by every derived class. This function is called orderingFunction which would carry the implementation of the ordering logic. In addition to that, a constructor should be written for the custom tensor ordering classes whose first 3 parameters have to be the reference to the tensor on which the ordering will be applied, the active modes of the tensor, and the name of the ordering, respectively. The fourth parameter is optional in that it can be skipped safely if the custom order does not need any parameters to work properly. Having declared our class, next is to create its source file named AddingTensorOrdering.cpp under the directory SparseViz/src/Tensor/Orderings. AddingTensorOrdering.cpp #include \"AddingTensorOrdering.h\" AddingTensorOrdering:: AddingTensorOrdering (SparseTensor &tensor, const std::vector<vType>& active_modes, std::string orderingName, std::string orderingParameters) : TensorOrdering(tensor, active_modes, orderingName, 5) { // Ordering parameters could be parsed (remember the delimiter is '/') // and appropriate private member variables could be set here } void AddingTensorOrdering::orderingFunction() { vType tensorOrder = this->getTensor().getOrder(); orderedDimensions = new vType*[tensorOrder]; for (int i = 0; i != tensorOrder; ++i) { orderedDimensions[i] = new vType[dims[i]]; } // Your ordering function logic goes here } There are a couple of important parts in the source code that require careful attention. The first is the initialization of the base class TensorOrdering in the constructor of the AddingTensorOrdering class. TensorOrdering expects the following parameters to be provided. SparseTensor& tensor const std::vector & active_modes std::string orderingName unsigned int orderingFunctionPrice = 0 The first 3 parameters, matrix, active_modes, and orderingName, could easily be provided to the parent class with the constructor parameters of the child class. The last parameter is an integer between 0 to 10 representing the overhead of the ordering function. Although it has a default value of 0, we recommend custom ordering derived classes to specify this value, as appropriate values could increase the performance of the program. For our ordering class, we will assume that it has an orderingFunction overhead value of 5. The last important remark that we need to make is that in the custom tensor orderings, a matrix should be generated by the orderingFunction. This matrix is a protected member variable of TensorOrdering called orderedDimensions that would keep track of the new locations of each dimension after the ordering is implemented. This matrix should be allocated on the heap as shown in the above code snippet. The custom tensor ordering class is not responsible for deleting this matrix, as the base TensorOrdering class will safely handle this.","title":"Step 1: Creating a Custom Ordering Class"},{"location":"addingTensorOrdering/#step-2-adding-files-into-cmakeliststxt","text":"In the former step, we created our header file and source file for our class named AddingTensorOrdering. In this step, we are going to include these files in our build automation tool. SparseViz utilizes CMake as its build system. In the CMakeLists.txt file located under the project directory, we should include our header file under the HEADER_FILES environment variable and include our source under the SOURCE_FILES environment variable, like so: CMakeLists.txt set(HEADER_FILES --- OTHER HEADER FILES (CROPPED) --- include/Tensor/Orderings/AddingTensorOrdering.h ) set(SOURCE_FILES --- OTHER SOURCE FILES (CROPPED) --- src/Tensor/Orderings/AddingTensorOrdering.cpp )","title":"Step 2: Adding Files into CMakeLists.txt"},{"location":"addingTensorOrdering/#step-3-adding-ordering-definition-into-sparsevizengine","text":"As the last step, we are going to add our ordering class definition into SparseVizEngine and allow the library to identify the presence of this ordering. As our first job, we are going to include our custom ordering class' header file into the SparseVizEngine.h: SparseVizEngine.h #include \"AddingTensorOrdering.h\" After that, we are going to add the definition of the class to the tensor ordering factory function located in the source file of the SparseVizEngine SparseVizEngine.cpp TensorOrdering *SparseVizEngine::tensorOrderingFactory(SparseTensor&tensor, const std::vector<vType>& active_modes, std::string orderingClassName, std::string orderingName, std::string orderingParameters) { --- OTHER ORDERING CLASSES (CROPPED) --- else if (orderingClassName == \"AddingTensorOrdering\") { return new AddingTensorOrdering(tensor, active_modes, orderingName, orderingParameters); } return nullptr; } Having done this, we can easily run this ordering from within the config file by indicating it under the section *TENSOR_ORDERINGS*, like so: config *TENSOR_ORDERINGS* AddingTensorOrdering | WeHaveAddedATensorOrdering | Param1/Param2/Param3 This concludes tutorial 3, the way to add tensor orderings into the library.","title":"Step 3: Adding Ordering Definition Into SparseVizEngine"},{"location":"configUse/","text":"Tutorial 1: How to Use the Config File The config file in SparseViz plays a crucial role, allowing the library to function effectively without the need for writing additional C/C++ code. It facilitates the use of pre-implemented orderings and kernels, enabling users to visualize matrices and tensors efficiently. This tutorial aims to guide you through the nuances of effectively utilizing the config file. In SparseViz, the config file is seperated into various sections with each of which adding different functionality to the config file. These sections are prefixed and suffixed with * to notice the config file reader that they are section headings. Here are the sections that are currently available for use within SparseViz: *LICENCES* This is the section under which every license should be indicated, like so: RABBIT_LICENCE = rabbit_licence.txt If you lack certain licenses, you should indicate their absence with \"None\". *SETTINGS* This is perhaps the most important section of the config file. Under which you should indicate various settings that are going to determine how your library is going to be initiated. Here are all the settings that can or should be given under this section, as well as their explanations as to what they are doing. IMPORTANT REMARKS Settings prefixed with * indicate that its explicit definition is mandatory in the config file, otherwise program will prompt a runtime error. Settings prefixed with ? indicates that its explicit definition is mandatory under certain conditions, which will be explained at the end of this tutorial. The absence of them will prompt a runtime error if these conditions are met. LOG_FILE LOG_FILE = [YOUR CSV PATH] SparseViz provides a performance logger that is accessible upon the termination of the program to showcase the details of each of the operations made with sparse data structures. This setting determines the path of the CSV to which the performance logging is going to be written. TIMING_LOG TIMING_LOG = [YOUR BOOLEAN VALUE] // Default = true In addition to providing a CSV file upon termination, SparseViz is also able to log the performance values onto the terminal if requested by this setting. Enabling this is going to make every one of the performance reports to be logged onto the terminal. EXPORT_ORDERED_SPARSE_STRUCTURES EXPORT_ORDERED_SPARSE_STRUCTURES = [YOUR BOOLEAN VALUE] // Default = true As indicated in the introduction, SparseViz can export and save sparse structures onto files for easy retrieval in further usage. This setting determines whether sparse structures having gone through some type of order in the current run should be written into the disk. USE_EXISTING_ORDERED_SPARSE_STRUCTURES USE_EXISTING_ORDERED_SPARSE_STRUCTURES = [YOUR BOOLEAN VALUE] // Default = true This setting determines whether ordered sparse structures having been written into disk previously are allowed to be read in the subsequent runs. EXPORT_ORDERINGS EXPORT_ORDERINGS = [YOUR BOOLEAN VALUE] // Default = true Similar to EXPORT_ORDERED_SPARSE_STRUCTURES, this setting determines whether orderings that have been made in the current run should be written into the disk. USE_EXISTING_ORDERINGS USE_EXISTING_ORDERINGS = [YOUR BOOLEAN VALUE] // Default = true Similar to USE_EXISTING_ORDERED_SPARSE_STRUCTURES, this setting determines whether ordering having written into disk previously is allowed to be read in the subsequent runs. * PROJECT_DIR PROJECT_DIR = [YOUR PATH TO PROJECT DIRECTORY] This setting should be set to the absolute path of the directory under which SparseViz is located. ? MATRIX_FILES_DIR MATRIX_FILES_DIR = [YOUR PATH TO MATRIX FILES DIRECTORY] This setting is set to the absolute path of the directory under which your matrix files (ones ending with .mtx or .mtx.bin) are located. ? MATRIX_ORDERING_FILES_DIR MATRIX_ORDERING_FILES_DIR = [YOUR PATH TO MATRIX ORDERING FILES DIRECTORY] This setting is set to the absolute path of the directory under which your matrix ordering files (ones ending with .bin) are located. ? MATRIX_VISUALIZATION_FILES_DIR MATRIX_VISUALIZATION_FILES_DIR = [YOUR PATH TO MATRIX VISUALIZATION FILES DIR] This setting is set to the absolute path of the directory into which matrix visualization files are going to be generated. Upon termination of the program, all visualization-related outputs are going to be found there. ? TENSOR_FILES_DIR TENSOR_FILES_DIR = [YOUR PATH TO TENSOR FILES DIRECTORY] This setting is set to the absolute path of the directory under which your tensor files (ones ending with .tns or .tns.bin) are located. ? TENSOR_ORDERING_FILES_DIR TENSOR_ORDERING_FILES_DIR = [YOUR PATH TO TENSOR ORDERING FILES DIRECTORY] This setting is set to the absolute path of the directory under which your tensor ordering files (ones ending with .bin) are located. ? TENSOR_VISUALIZATION_FILES_DIR TENSOR_VISUALIZATION_FILES_DIR = [YOUR PATH TO TENSOR VISUALIZATION FILES DIR] This setting is set to the absolute path of the directory into which tensor visualization files are going to be generated. Upon termination of the program, all visualization-related outputs are going to be found there. LOGO_PATH LOGO_PATH = [YOUR PATH FOR THE LOGO] This setting is set to the absolute path of the logo that will be used for the logo of every HTML document generated. FAVICON_PATH FAVICON_PATH = [YOUR PATH FOR THE FAVICON] This setting is set to the absolute path of the logo that will be used for the favicon of every HTML document generated. MAX_DIM MAX_DIM = [YOUR INTEGER] // Default = 64 This setting is set to an integer representing the maximum dimension that can be seen in the visualization files. * ZOO_TYPE ZOO_TYPE = [YOUR ZOO TYPE] // Currently availables are: {\"MAT\", \"MATORD\", \"TENS\", \"TENSORD\", \"FULLTENSOR\"} This setting is set to one of the 5 available zoo types that SparseViz currently supports. What each of them does will be explained at the end of this tutorial. * CHART_TYPE CHART_TYPE = [YOUR CHART TYPE] // Currently availables are: {\"NNZ\", \"ABS\"} This setting is set to one of 2 available chart types that SparseViz currently supports. It determines the chart type that will be used in the visualization, whether it'll be nonzero or absolute value-based. *MATRICES* This section is for providing every one of the .mtx filenames that will be used throughout the execution of the program. Giving only the filename with its appropriate extension (probably .mtx) is enough as their full path can be inferred with the matrix file directory setting you have indicated in the former section. Every .mtx filename should allocate a separate line. *MATRIX_ORDERINGS* This section provides every matrix ordering that will be used throughout the execution of the program. The usage should be as follows: [YOUR MATRIX ORDERING CLASS NAME] [YOUR ORDERING NAME] [YOUR PARAMETERS GIVEN TO THE ORDERING CLASS CONSTRUCTOR SEPARATED WITH '/'] Indicating parameters to the ordering class constructor can be skipped safely, if and only if the ordering constructor does not expect any. Every ordering definition should allocate a separate line. *TENSORS* This section provides every one of the .tns filenames that will be used throughout the execution of the program. Giving only the filename with its appropriate extension (probably .tns) is enough as their full path can be inferred with the tensor file directory setting you have indicated in the former section. Every .tns filename should allocate a separate line. *TENSOR_ORDERINGS* This section provides every tensor ordering that will be used throughout the execution of the program. The usage should be as follows: [YOUR TENSOR ORDERING CLASS NAME] | [YOUR ORDERING NAME] | [YOUR PARAMETERS GIVEN TO THE ORDERING CLASS CONSTRUCTOR SEPARATED WITH '/'] Indicating parameters to the ordering class constructor can be skipped safely, if and only if the ordering constructor does not expect any. Every ordering definition should allocate a separate line. *MATRIX_KERNELS* This section is for providing every CPU matrix kernel that will be executed on your ordered sparse matrices. The usage should be as follows: [YOUR KERNEL NAME] | [YOUR THREAD COUNTS] | [YOUR SCHEDULING POLICY] | [YOUR CHUNK SIZE] | [YOUR N_RUN] | [YOUR N_IGNORE] Because we have made matrix kernel parallelization possible with OpenMP, you are required to provide necessary OMP arguments while running your kernels. Currently, 3 arguments could be set from the config file to arrange your parallel environment, which are: Setting Thread Counts: This is used for indicating the number of threads that will be working during your kernel's execution. If you want to test your kernels multiple times, with each of which having different thread counts working on, you can give an array of thread counts directly from within the config file by separating its elements with a delimiter of '/', like so: 1/2/4/8/16. Setting Scheduling Policy: OpenMP scheduling policies can be set from the config file as well. Available scheduling policies to be set are: {\"static\", \"auto\", \"dynamic\", \"guided\"}. Setting Chunk Size: One last parameter that can be set from the config file is chunk size. Its use is simply indicating an integer to determine the chunk size of the parallel environment. N_RUN parameter determines the number of times that your kernel is going to get repeated and N_IGNORE determines the first number of executions to be ignored. Every matrix kernel definition should allocate a separate line in the config file. *GPU_MATRIX_KERNELS* This section is for providing every GPU matrix kernel that will be executed on your ordered sparse matrices. The usage should be as follows: [YOUR KERNEL NAME] | [YOUR GRID SIZE] | [YOUR BLOCK SIZES] | [YOUR N_RUN] | [YOUR N_IGNORE] Because we have made matrix GPU kernel parallelization possible with Cuda, you are required to provide necessary Cuda arguments while launching your kernels. Currently, 2 arguments could be set from the config file to arrange your parallel environment, which are: Setting Grid Size: While launching Cuda kernels, 2 parameters are required to be set. One of them is the size of the grid which determines the number of blocks that it is going to include in it. Similar to the CPU Matrix Kernel thread count argument, the grid size parameter could be given as an array of grid sizes where each element is separated from one another with a delimiter of '/'. Setting Block Size: The other argument that Cuda dictates to be set while launching GPU kernels is block sizes that determine the number of threads that will be working within each block. Similar to the CPU Matrix Kernel thread count argument, the block size parameter could be given as an array of block sizes where each element is separated from one another with a delimiter of '/'. One important thing to consider in the above 2 settings is that their length should be equal to each other -if they are given as an array-, as they will be zipped while processing. N_RUN and N_IGNORE are the same as their counterparts in CPU Matrix Kernels. Every GPU matrix kernel definition should allocate a separate line in the config file. *TENSOR_KERNELS* This section is for providing every CPU tensor kernel that will be executed on your ordered sparse matrices. The usage should be as follows: [YOUR KERNEL NAME] | [YOUR THREAD COUNTS] | [YOUR SCHEDULING POLICY] | [YOUR CHUNK SIZE] | [YOUR N_RUN] | [YOUR N_IGNORE] Because we have made tensor kernel parallelization possible with OpenMP, you are required to provide necessary OMP arguments while running your kernels. Currently, 3 arguments could be set from the config file to arrange your parallel environment, which are: Setting Thread Counts: This is used for indicating the number of threads that will be working during your kernel's execution. If you want to test your kernels multiple times, with each of which having different thread counts working on, you can give an array of thread counts directly from within the config file by separating its elements with a delimiter of '/', like so: 1/2/4/8/16. Setting Scheduling Policy: OpenMP scheduling policies can be set from the config file as well. Available scheduling policies to be set are: {\"static\", \"auto\", \"dynamic\", \"guided\"}. Setting Chunk Size: One last parameter that can be set from the config file is chunk size. Its use is simply indicating an integer to determine the chunk size of the parallel environment. N_RUN parameter determines the number of times that your kernel is going to get repeated and N_IGNORE determines the first number of executions to be ignored. Every tensor kernel definition should allocate a separate line in the config file. *GPU_TENSOR_KERNELS* This section is for providing every GPU tensor kernel that will be executed on your ordered sparse matrices. The usage should be as follows: [YOUR KERNEL NAME] | [YOUR GRID SIZE] | [YOUR BLOCK SIZES] | [YOUR N_RUN] | [YOUR N_IGNORE] Because we have made tensor GPU kernel parallelization possible with Cuda, you are required to provide necessary Cuda arguments while launching your kernels. Currently, 2 arguments could be set from the config file to arrange your parallel environment, which are: Setting Grid Size: While launching Cuda kernels, 2 parameters are required to be set. One of them is the size of the grid which determines the number of blocks that it is going to include in it. Similar to the CPU Tensor Kernel thread count argument, the grid size parameter could be given as an array of grid sizes where each element is separated from one another with a delimiter of '/'. Setting Block Size: The other argument that Cuda dictates to be set while launching GPU kernels is block sizes that determine the number of threads that will be working within each block. Similar to the CPU Tensor Kernel thread count argument, the block size parameter could be given as an array of block sizes where each element is separated from one another with a delimiter of '/'. One important thing to consider in the above 2 settings is that their length should be equal to each other -if they are given as an array-, as they will be zipped while processing. N_RUN and N_IGNORE are the same as their counterparts in CPU Matrix Kernels. Every GPU tensor kernel definition should allocate a separate line in the config file. ZOO TYPES One final remark that is left unmentioned related to the config file is what each ZOO_TYPE does. ZOO_TYPE determines the library's mode of running. As said previously, 5 zoo types could be used for now. Each one of them is explained as follows: \"MAT\" MAT ZOO_TYPE enables the library to work with matrices. Its use requires the following config settings to be defined explicitly: MATRIX_FILES_DIR MATRIX_ORDERING_FILES_DIR MATRIX_VISUALIZATION_FILES_DIR While it would activate the matrix flow of the library, one feature that is separated from other matrices ZOO_TYPE is in its way of visualizing matrices. In the MAT ZOO_TYPE, separate html files are generated for every one of the matrices whose filename is mentioned under the *MATRICES* section. Orderings implemented on them will be visualized one under the other within the same file whose name is typically determined by the matrix name itself. \"MATORD\" MATORD ZOO_TYPE enables the library to work with matrices as well. Its use requires the same config settings to be defined explicitly as MAT ZOO_TYPE: MATRIX_FILES_DIR MATRIX_ORDERING_FILES_DIR MATRIX_VISUALIZATION_FILES_DIR While it would activate the matrix flow of the library, one feature that it separated from the other available matrix-based ZOO_TYPE is its unique way of visualizing matrices. In the MATORD ZOO_TYPE, separate HTML files are generated for every one of the orderings whose properties are mentioned under the *MATRIX_ORDERINGS* section. Matrices on which the very same ordering is implemented are visualized one under the other within the same file whose name is typically determined by the name of the ordering itself. \"TENS\" TENS ZOO_TYPE enables the library to work with tensors. Its use requires the following config settings to be defined explicitly: TENSOR_FILES_DIR TENSOR_ORDERING_FILES_DIR TENSOR_VISUALIZATION_FILES_DIR While it would activate the tensor flow of the library, one feature that is separated from other available tensor-based ZOO_TYPEs is in its way of visualizing tensors. In the TENS ZOO_TYPE, separate html files are generated for every one of the tensors whose filename is mentioned under the *TENSORS* section. Orderings implemented on them will be visualized one under the other within the same file whose name is typically determined by the tensor name itself. \"TENSORD\" TENSORD ZOO_TYPE enables the library to work with tensors as well. Its use requires the same config settings to be defined explicitly as TENS ZOO_TYPE: TENSOR_FILES_DIR TENSOR_ORDERING_FILES_DIR TENSOR_VISUALIZATION_FILES_DIR While it would activate the tensor flow of the library, one feature that it separated from the other available tensor-based ZOO_TYPEs is its unique way of visualizing matrices. In the TENSORD ZOO_TYPE, separate HTML files are generated for every one of the orderings whose properties are mentioned under the *TENSOR_ORDERINGS* section. Tensors on which the very same ordering is implemented are visualized one under the other within the same file whose name is typically determined by the name of the ordering itself. \"FULLTENSOR\" [TO BE COMPLETED] Having set our config file up, we can run our library properly by executing the executable file of SparseViz with the only argument pointing to the absolute path of the config file we have built.","title":"Config File"},{"location":"configUse/#tutorial-1-how-to-use-the-config-file","text":"The config file in SparseViz plays a crucial role, allowing the library to function effectively without the need for writing additional C/C++ code. It facilitates the use of pre-implemented orderings and kernels, enabling users to visualize matrices and tensors efficiently. This tutorial aims to guide you through the nuances of effectively utilizing the config file. In SparseViz, the config file is seperated into various sections with each of which adding different functionality to the config file. These sections are prefixed and suffixed with * to notice the config file reader that they are section headings. Here are the sections that are currently available for use within SparseViz:","title":"Tutorial 1: How to Use the Config File"},{"location":"configUse/#licences","text":"This is the section under which every license should be indicated, like so: RABBIT_LICENCE = rabbit_licence.txt If you lack certain licenses, you should indicate their absence with \"None\".","title":"*LICENCES*"},{"location":"configUse/#settings","text":"This is perhaps the most important section of the config file. Under which you should indicate various settings that are going to determine how your library is going to be initiated. Here are all the settings that can or should be given under this section, as well as their explanations as to what they are doing.","title":"*SETTINGS*"},{"location":"configUse/#important-remarks","text":"Settings prefixed with * indicate that its explicit definition is mandatory in the config file, otherwise program will prompt a runtime error. Settings prefixed with ? indicates that its explicit definition is mandatory under certain conditions, which will be explained at the end of this tutorial. The absence of them will prompt a runtime error if these conditions are met.","title":"IMPORTANT REMARKS"},{"location":"configUse/#log_file","text":"LOG_FILE = [YOUR CSV PATH] SparseViz provides a performance logger that is accessible upon the termination of the program to showcase the details of each of the operations made with sparse data structures. This setting determines the path of the CSV to which the performance logging is going to be written.","title":"LOG_FILE"},{"location":"configUse/#timing_log","text":"TIMING_LOG = [YOUR BOOLEAN VALUE] // Default = true In addition to providing a CSV file upon termination, SparseViz is also able to log the performance values onto the terminal if requested by this setting. Enabling this is going to make every one of the performance reports to be logged onto the terminal.","title":"TIMING_LOG"},{"location":"configUse/#export_ordered_sparse_structures","text":"EXPORT_ORDERED_SPARSE_STRUCTURES = [YOUR BOOLEAN VALUE] // Default = true As indicated in the introduction, SparseViz can export and save sparse structures onto files for easy retrieval in further usage. This setting determines whether sparse structures having gone through some type of order in the current run should be written into the disk.","title":"EXPORT_ORDERED_SPARSE_STRUCTURES"},{"location":"configUse/#use_existing_ordered_sparse_structures","text":"USE_EXISTING_ORDERED_SPARSE_STRUCTURES = [YOUR BOOLEAN VALUE] // Default = true This setting determines whether ordered sparse structures having been written into disk previously are allowed to be read in the subsequent runs.","title":"USE_EXISTING_ORDERED_SPARSE_STRUCTURES"},{"location":"configUse/#export_orderings","text":"EXPORT_ORDERINGS = [YOUR BOOLEAN VALUE] // Default = true Similar to EXPORT_ORDERED_SPARSE_STRUCTURES, this setting determines whether orderings that have been made in the current run should be written into the disk.","title":"EXPORT_ORDERINGS"},{"location":"configUse/#use_existing_orderings","text":"USE_EXISTING_ORDERINGS = [YOUR BOOLEAN VALUE] // Default = true Similar to USE_EXISTING_ORDERED_SPARSE_STRUCTURES, this setting determines whether ordering having written into disk previously is allowed to be read in the subsequent runs.","title":"USE_EXISTING_ORDERINGS"},{"location":"configUse/#project_dir","text":"PROJECT_DIR = [YOUR PATH TO PROJECT DIRECTORY] This setting should be set to the absolute path of the directory under which SparseViz is located.","title":"* PROJECT_DIR"},{"location":"configUse/#matrix_files_dir","text":"MATRIX_FILES_DIR = [YOUR PATH TO MATRIX FILES DIRECTORY] This setting is set to the absolute path of the directory under which your matrix files (ones ending with .mtx or .mtx.bin) are located.","title":"? MATRIX_FILES_DIR"},{"location":"configUse/#matrix_ordering_files_dir","text":"MATRIX_ORDERING_FILES_DIR = [YOUR PATH TO MATRIX ORDERING FILES DIRECTORY] This setting is set to the absolute path of the directory under which your matrix ordering files (ones ending with .bin) are located.","title":"? MATRIX_ORDERING_FILES_DIR"},{"location":"configUse/#matrix_visualization_files_dir","text":"MATRIX_VISUALIZATION_FILES_DIR = [YOUR PATH TO MATRIX VISUALIZATION FILES DIR] This setting is set to the absolute path of the directory into which matrix visualization files are going to be generated. Upon termination of the program, all visualization-related outputs are going to be found there.","title":"? MATRIX_VISUALIZATION_FILES_DIR"},{"location":"configUse/#tensor_files_dir","text":"TENSOR_FILES_DIR = [YOUR PATH TO TENSOR FILES DIRECTORY] This setting is set to the absolute path of the directory under which your tensor files (ones ending with .tns or .tns.bin) are located.","title":"? TENSOR_FILES_DIR"},{"location":"configUse/#tensor_ordering_files_dir","text":"TENSOR_ORDERING_FILES_DIR = [YOUR PATH TO TENSOR ORDERING FILES DIRECTORY] This setting is set to the absolute path of the directory under which your tensor ordering files (ones ending with .bin) are located.","title":"? TENSOR_ORDERING_FILES_DIR"},{"location":"configUse/#tensor_visualization_files_dir","text":"TENSOR_VISUALIZATION_FILES_DIR = [YOUR PATH TO TENSOR VISUALIZATION FILES DIR] This setting is set to the absolute path of the directory into which tensor visualization files are going to be generated. Upon termination of the program, all visualization-related outputs are going to be found there.","title":"? TENSOR_VISUALIZATION_FILES_DIR"},{"location":"configUse/#logo_path","text":"LOGO_PATH = [YOUR PATH FOR THE LOGO] This setting is set to the absolute path of the logo that will be used for the logo of every HTML document generated.","title":"LOGO_PATH"},{"location":"configUse/#favicon_path","text":"FAVICON_PATH = [YOUR PATH FOR THE FAVICON] This setting is set to the absolute path of the logo that will be used for the favicon of every HTML document generated.","title":"FAVICON_PATH"},{"location":"configUse/#max_dim","text":"MAX_DIM = [YOUR INTEGER] // Default = 64 This setting is set to an integer representing the maximum dimension that can be seen in the visualization files.","title":"MAX_DIM"},{"location":"configUse/#zoo_type","text":"ZOO_TYPE = [YOUR ZOO TYPE] // Currently availables are: {\"MAT\", \"MATORD\", \"TENS\", \"TENSORD\", \"FULLTENSOR\"} This setting is set to one of the 5 available zoo types that SparseViz currently supports. What each of them does will be explained at the end of this tutorial.","title":"* ZOO_TYPE"},{"location":"configUse/#chart_type","text":"CHART_TYPE = [YOUR CHART TYPE] // Currently availables are: {\"NNZ\", \"ABS\"} This setting is set to one of 2 available chart types that SparseViz currently supports. It determines the chart type that will be used in the visualization, whether it'll be nonzero or absolute value-based.","title":"* CHART_TYPE"},{"location":"configUse/#matrices","text":"This section is for providing every one of the .mtx filenames that will be used throughout the execution of the program. Giving only the filename with its appropriate extension (probably .mtx) is enough as their full path can be inferred with the matrix file directory setting you have indicated in the former section. Every .mtx filename should allocate a separate line.","title":"*MATRICES*"},{"location":"configUse/#matrix_orderings","text":"This section provides every matrix ordering that will be used throughout the execution of the program. The usage should be as follows: [YOUR MATRIX ORDERING CLASS NAME] [YOUR ORDERING NAME] [YOUR PARAMETERS GIVEN TO THE ORDERING CLASS CONSTRUCTOR SEPARATED WITH '/'] Indicating parameters to the ordering class constructor can be skipped safely, if and only if the ordering constructor does not expect any. Every ordering definition should allocate a separate line.","title":"*MATRIX_ORDERINGS*"},{"location":"configUse/#tensors","text":"This section provides every one of the .tns filenames that will be used throughout the execution of the program. Giving only the filename with its appropriate extension (probably .tns) is enough as their full path can be inferred with the tensor file directory setting you have indicated in the former section. Every .tns filename should allocate a separate line.","title":"*TENSORS*"},{"location":"configUse/#tensor_orderings","text":"This section provides every tensor ordering that will be used throughout the execution of the program. The usage should be as follows: [YOUR TENSOR ORDERING CLASS NAME] | [YOUR ORDERING NAME] | [YOUR PARAMETERS GIVEN TO THE ORDERING CLASS CONSTRUCTOR SEPARATED WITH '/'] Indicating parameters to the ordering class constructor can be skipped safely, if and only if the ordering constructor does not expect any. Every ordering definition should allocate a separate line.","title":"*TENSOR_ORDERINGS*"},{"location":"configUse/#matrix_kernels","text":"This section is for providing every CPU matrix kernel that will be executed on your ordered sparse matrices. The usage should be as follows: [YOUR KERNEL NAME] | [YOUR THREAD COUNTS] | [YOUR SCHEDULING POLICY] | [YOUR CHUNK SIZE] | [YOUR N_RUN] | [YOUR N_IGNORE] Because we have made matrix kernel parallelization possible with OpenMP, you are required to provide necessary OMP arguments while running your kernels. Currently, 3 arguments could be set from the config file to arrange your parallel environment, which are:","title":"*MATRIX_KERNELS*"},{"location":"configUse/#setting-thread-counts","text":"This is used for indicating the number of threads that will be working during your kernel's execution. If you want to test your kernels multiple times, with each of which having different thread counts working on, you can give an array of thread counts directly from within the config file by separating its elements with a delimiter of '/', like so: 1/2/4/8/16.","title":"Setting Thread Counts:"},{"location":"configUse/#setting-scheduling-policy","text":"OpenMP scheduling policies can be set from the config file as well. Available scheduling policies to be set are: {\"static\", \"auto\", \"dynamic\", \"guided\"}.","title":"Setting Scheduling Policy:"},{"location":"configUse/#setting-chunk-size","text":"One last parameter that can be set from the config file is chunk size. Its use is simply indicating an integer to determine the chunk size of the parallel environment. N_RUN parameter determines the number of times that your kernel is going to get repeated and N_IGNORE determines the first number of executions to be ignored. Every matrix kernel definition should allocate a separate line in the config file.","title":"Setting Chunk Size:"},{"location":"configUse/#gpu_matrix_kernels","text":"This section is for providing every GPU matrix kernel that will be executed on your ordered sparse matrices. The usage should be as follows: [YOUR KERNEL NAME] | [YOUR GRID SIZE] | [YOUR BLOCK SIZES] | [YOUR N_RUN] | [YOUR N_IGNORE] Because we have made matrix GPU kernel parallelization possible with Cuda, you are required to provide necessary Cuda arguments while launching your kernels. Currently, 2 arguments could be set from the config file to arrange your parallel environment, which are:","title":"*GPU_MATRIX_KERNELS*"},{"location":"configUse/#setting-grid-size","text":"While launching Cuda kernels, 2 parameters are required to be set. One of them is the size of the grid which determines the number of blocks that it is going to include in it. Similar to the CPU Matrix Kernel thread count argument, the grid size parameter could be given as an array of grid sizes where each element is separated from one another with a delimiter of '/'.","title":"Setting Grid Size:"},{"location":"configUse/#setting-block-size","text":"The other argument that Cuda dictates to be set while launching GPU kernels is block sizes that determine the number of threads that will be working within each block. Similar to the CPU Matrix Kernel thread count argument, the block size parameter could be given as an array of block sizes where each element is separated from one another with a delimiter of '/'. One important thing to consider in the above 2 settings is that their length should be equal to each other -if they are given as an array-, as they will be zipped while processing. N_RUN and N_IGNORE are the same as their counterparts in CPU Matrix Kernels. Every GPU matrix kernel definition should allocate a separate line in the config file.","title":"Setting Block Size:"},{"location":"configUse/#tensor_kernels","text":"This section is for providing every CPU tensor kernel that will be executed on your ordered sparse matrices. The usage should be as follows: [YOUR KERNEL NAME] | [YOUR THREAD COUNTS] | [YOUR SCHEDULING POLICY] | [YOUR CHUNK SIZE] | [YOUR N_RUN] | [YOUR N_IGNORE] Because we have made tensor kernel parallelization possible with OpenMP, you are required to provide necessary OMP arguments while running your kernels. Currently, 3 arguments could be set from the config file to arrange your parallel environment, which are:","title":"*TENSOR_KERNELS*"},{"location":"configUse/#setting-thread-counts_1","text":"This is used for indicating the number of threads that will be working during your kernel's execution. If you want to test your kernels multiple times, with each of which having different thread counts working on, you can give an array of thread counts directly from within the config file by separating its elements with a delimiter of '/', like so: 1/2/4/8/16.","title":"Setting Thread Counts:"},{"location":"configUse/#setting-scheduling-policy_1","text":"OpenMP scheduling policies can be set from the config file as well. Available scheduling policies to be set are: {\"static\", \"auto\", \"dynamic\", \"guided\"}.","title":"Setting Scheduling Policy:"},{"location":"configUse/#setting-chunk-size_1","text":"One last parameter that can be set from the config file is chunk size. Its use is simply indicating an integer to determine the chunk size of the parallel environment. N_RUN parameter determines the number of times that your kernel is going to get repeated and N_IGNORE determines the first number of executions to be ignored. Every tensor kernel definition should allocate a separate line in the config file.","title":"Setting Chunk Size:"},{"location":"configUse/#gpu_tensor_kernels","text":"This section is for providing every GPU tensor kernel that will be executed on your ordered sparse matrices. The usage should be as follows: [YOUR KERNEL NAME] | [YOUR GRID SIZE] | [YOUR BLOCK SIZES] | [YOUR N_RUN] | [YOUR N_IGNORE] Because we have made tensor GPU kernel parallelization possible with Cuda, you are required to provide necessary Cuda arguments while launching your kernels. Currently, 2 arguments could be set from the config file to arrange your parallel environment, which are:","title":"*GPU_TENSOR_KERNELS*"},{"location":"configUse/#setting-grid-size_1","text":"While launching Cuda kernels, 2 parameters are required to be set. One of them is the size of the grid which determines the number of blocks that it is going to include in it. Similar to the CPU Tensor Kernel thread count argument, the grid size parameter could be given as an array of grid sizes where each element is separated from one another with a delimiter of '/'.","title":"Setting Grid Size:"},{"location":"configUse/#setting-block-size_1","text":"The other argument that Cuda dictates to be set while launching GPU kernels is block sizes that determine the number of threads that will be working within each block. Similar to the CPU Tensor Kernel thread count argument, the block size parameter could be given as an array of block sizes where each element is separated from one another with a delimiter of '/'. One important thing to consider in the above 2 settings is that their length should be equal to each other -if they are given as an array-, as they will be zipped while processing. N_RUN and N_IGNORE are the same as their counterparts in CPU Matrix Kernels. Every GPU tensor kernel definition should allocate a separate line in the config file.","title":"Setting Block Size:"},{"location":"configUse/#zoo-types","text":"One final remark that is left unmentioned related to the config file is what each ZOO_TYPE does. ZOO_TYPE determines the library's mode of running. As said previously, 5 zoo types could be used for now. Each one of them is explained as follows:","title":"ZOO TYPES"},{"location":"configUse/#mat","text":"MAT ZOO_TYPE enables the library to work with matrices. Its use requires the following config settings to be defined explicitly: MATRIX_FILES_DIR MATRIX_ORDERING_FILES_DIR MATRIX_VISUALIZATION_FILES_DIR While it would activate the matrix flow of the library, one feature that is separated from other matrices ZOO_TYPE is in its way of visualizing matrices. In the MAT ZOO_TYPE, separate html files are generated for every one of the matrices whose filename is mentioned under the *MATRICES* section. Orderings implemented on them will be visualized one under the other within the same file whose name is typically determined by the matrix name itself.","title":"\"MAT\""},{"location":"configUse/#matord","text":"MATORD ZOO_TYPE enables the library to work with matrices as well. Its use requires the same config settings to be defined explicitly as MAT ZOO_TYPE: MATRIX_FILES_DIR MATRIX_ORDERING_FILES_DIR MATRIX_VISUALIZATION_FILES_DIR While it would activate the matrix flow of the library, one feature that it separated from the other available matrix-based ZOO_TYPE is its unique way of visualizing matrices. In the MATORD ZOO_TYPE, separate HTML files are generated for every one of the orderings whose properties are mentioned under the *MATRIX_ORDERINGS* section. Matrices on which the very same ordering is implemented are visualized one under the other within the same file whose name is typically determined by the name of the ordering itself.","title":"\"MATORD\""},{"location":"configUse/#tens","text":"TENS ZOO_TYPE enables the library to work with tensors. Its use requires the following config settings to be defined explicitly: TENSOR_FILES_DIR TENSOR_ORDERING_FILES_DIR TENSOR_VISUALIZATION_FILES_DIR While it would activate the tensor flow of the library, one feature that is separated from other available tensor-based ZOO_TYPEs is in its way of visualizing tensors. In the TENS ZOO_TYPE, separate html files are generated for every one of the tensors whose filename is mentioned under the *TENSORS* section. Orderings implemented on them will be visualized one under the other within the same file whose name is typically determined by the tensor name itself.","title":"\"TENS\""},{"location":"configUse/#tensord","text":"TENSORD ZOO_TYPE enables the library to work with tensors as well. Its use requires the same config settings to be defined explicitly as TENS ZOO_TYPE: TENSOR_FILES_DIR TENSOR_ORDERING_FILES_DIR TENSOR_VISUALIZATION_FILES_DIR While it would activate the tensor flow of the library, one feature that it separated from the other available tensor-based ZOO_TYPEs is its unique way of visualizing matrices. In the TENSORD ZOO_TYPE, separate HTML files are generated for every one of the orderings whose properties are mentioned under the *TENSOR_ORDERINGS* section. Tensors on which the very same ordering is implemented are visualized one under the other within the same file whose name is typically determined by the name of the ordering itself.","title":"\"TENSORD\""},{"location":"configUse/#fulltensor","text":"[TO BE COMPLETED] Having set our config file up, we can run our library properly by executing the executable file of SparseViz with the only argument pointing to the absolute path of the config file we have built.","title":"\"FULLTENSOR\""},{"location":"licence/","text":"MIT License Copyright (c) 2024 SparCity project Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"Licence"}]}